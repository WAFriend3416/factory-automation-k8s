"""
Registry Consistency Checker
ì„¤ì • íŒŒì¼ë“¤ ê°„ ì •í•©ì„± ê²€ì¦ ë„êµ¬
- config/rules.sparql
- config/ontology.owl (+ TTL ë°±ì—…)
- config/model_registry.json
- querygoal/pipeline íŒ¨í„´ ê·œì¹™
"""
import json
import os
from typing import Dict, Any, List, Set, Optional, Tuple
from pathlib import Path
from rdflib import Graph, Namespace, URIRef
from rdflib.namespace import RDF, RDFS
import re


class RegistryConsistencyError(Exception):
    """ì •í•©ì„± ê²€ì‚¬ ì˜¤ë¥˜"""
    pass


class RegistryChecker:
    """ì„¤ì • íŒŒì¼ ì •í•©ì„± ê²€ì‚¬ê¸°"""

    def __init__(self, base_dir: Optional[str] = None):
        """
        Args:
            base_dir: í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        """
        if base_dir:
            self.base_dir = Path(base_dir)
        else:
            self.base_dir = Path(__file__).parent.parent.parent

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self.config_dir = self.base_dir / "config"
        self.rules_file = self.config_dir / "rules.sparql"
        self.ontology_file = self.config_dir / "ontology.owl"
        self.ttl_backup_file = self.base_dir.parent / "factory-automation-k8s-backup" / "ontology" / "factory_ontology_v2_final_corrected.ttl"
        self.registry_file = self.config_dir / "model_registry.json"
        self.pipeline_dir = self.base_dir / "querygoal" / "pipeline"

        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
        self.ex = Namespace("http://example.com/ontology#")

        # ê²€ì‚¬ ê²°ê³¼ ì €ì¥
        self.issues: List[Dict[str, Any]] = []

    def check_all(self) -> Dict[str, Any]:
        """
        ëª¨ë“  ì •í•©ì„± ê²€ì‚¬ ìˆ˜í–‰

        Returns:
            ê²€ì‚¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("ğŸ” Registry Consistency Check ì‹œì‘...")

        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        self._check_file_existence()

        # ë°ì´í„° ë¡œë“œ
        try:
            registry_data = self._load_model_registry()
            sparql_rules = self._load_sparql_rules()
            ontology_data = self._load_ontology_data()
            pattern_rules = self._load_pattern_rules()
        except Exception as e:
            self.issues.append({
                "type": "critical",
                "category": "file_loading",
                "message": f"Failed to load configuration files: {e}",
                "file": "multiple"
            })
            return self._generate_report()

        # ì •í•©ì„± ê²€ì‚¬ ìˆ˜í–‰
        self._check_goal_type_consistency(registry_data, sparql_rules, pattern_rules)
        self._check_model_purpose_mapping(registry_data, sparql_rules)
        self._check_model_registry_completeness(registry_data)
        self._check_ontology_action_sequences(ontology_data, pattern_rules)
        self._check_pipeline_stage_consistency(pattern_rules)

        return self._generate_report()

    def _check_file_existence(self) -> None:
        """í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        files_to_check = [
            (self.rules_file, "SPARQL Rules"),
            (self.registry_file, "Model Registry"),
            (self.pipeline_dir / "pattern_matcher.py", "Pattern Matcher")
        ]

        # ì˜¨í†¨ë¡œì§€ íŒŒì¼ ì²´í¬ (OWL ë˜ëŠ” TTL)
        if self.ontology_file.exists():
            files_to_check.append((self.ontology_file, "Ontology (OWL)"))
        elif self.ttl_backup_file.exists():
            files_to_check.append((self.ttl_backup_file, "Ontology (TTL Backup)"))
        else:
            self.issues.append({
                "type": "critical",
                "category": "missing_file",
                "message": "Neither ontology.owl nor TTL backup file found",
                "file": "config/ontology.*"
            })

        for file_path, description in files_to_check:
            if not file_path.exists():
                self.issues.append({
                    "type": "critical",
                    "category": "missing_file",
                    "message": f"{description} file not found",
                    "file": str(file_path.relative_to(self.base_dir))
                })

    def _load_model_registry(self) -> Dict[str, Any]:
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ"""
        if not self.registry_file.exists():
            return {"models": []}

        try:
            with open(self.registry_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except json.JSONDecodeError as e:
            self.issues.append({
                "type": "critical",
                "category": "parse_error",
                "message": f"Invalid JSON in model registry: {e}",
                "file": "config/model_registry.json"
            })
            return {"models": []}

    def _load_sparql_rules(self) -> str:
        """SPARQL ê·œì¹™ íŒŒì¼ ë¡œë“œ"""
        if not self.rules_file.exists():
            return ""

        try:
            with open(self.rules_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            self.issues.append({
                "type": "error",
                "category": "file_read",
                "message": f"Failed to read SPARQL rules: {e}",
                "file": "config/rules.sparql"
            })
            return ""

    def _load_ontology_data(self) -> Optional[Graph]:
        """ì˜¨í†¨ë¡œì§€ ë°ì´í„° ë¡œë“œ"""
        graph = None

        # OWL íŒŒì¼ ì‹œë„
        if self.ontology_file.exists():
            try:
                graph = Graph()
                graph.parse(self.ontology_file, format="xml")
                graph.bind("ex", self.ex)
            except Exception as e:
                self.issues.append({
                    "type": "warning",
                    "category": "parse_error",
                    "message": f"Failed to parse OWL ontology: {e}",
                    "file": "config/ontology.owl"
                })

        # TTL ë°±ì—… íŒŒì¼ ì‹œë„
        if not graph and self.ttl_backup_file.exists():
            try:
                graph = Graph()
                graph.parse(self.ttl_backup_file, format="turtle")
                graph.bind("ex", self.ex)
            except Exception as e:
                self.issues.append({
                    "type": "warning",
                    "category": "parse_error",
                    "message": f"Failed to parse TTL ontology: {e}",
                    "file": "factory-automation-k8s-backup/ontology/*.ttl"
                })

        return graph

    def _load_pattern_rules(self) -> Dict[str, Any]:
        """íŒ¨í„´ ë§¤ì¹­ ê·œì¹™ ë¡œë“œ"""
        pattern_file = self.pipeline_dir / "pattern_matcher.py"
        if not pattern_file.exists():
            return {}

        try:
            with open(pattern_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # GoalType enum ì¶”ì¶œ
            goal_types = set()
            enum_match = re.search(r'class GoalType\(Enum\):(.*?)(?=class|\Z)', content, re.DOTALL)
            if enum_match:
                enum_content = enum_match.group(1)
                for line in enum_content.split('\n'):
                    match = re.search(r'(\w+)\s*=\s*["\']([^"\']+)["\']', line)
                    if match:
                        goal_types.add(match.group(2))

            # íŒ¨í„´ ì¶”ì¶œ
            patterns = {}
            patterns_match = re.search(r'self\.patterns\s*=\s*{(.*?)}', content, re.DOTALL)
            if patterns_match:
                patterns_content = patterns_match.group(1)
                # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ASTë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ)
                current_goal = None
                for line in patterns_content.split('\n'):
                    line = line.strip()
                    if 'GoalType.' in line and ':' in line:
                        goal_match = re.search(r'GoalType\.(\w+)', line)
                        if goal_match:
                            current_goal = goal_match.group(1)
                            patterns[current_goal] = []

            return {
                "goal_types": goal_types,
                "patterns": patterns
            }

        except Exception as e:
            self.issues.append({
                "type": "warning",
                "category": "file_read",
                "message": f"Failed to read pattern rules: {e}",
                "file": "querygoal/pipeline/pattern_matcher.py"
            })
            return {}

    def _check_goal_type_consistency(self,
                                    registry_data: Dict[str, Any],
                                    sparql_rules: str,
                                    pattern_rules: Dict[str, Any]) -> None:
        """Goal íƒ€ì… ì¼ê´€ì„± í™•ì¸"""
        # ê° ì†ŒìŠ¤ì—ì„œ Goal íƒ€ì… ì¶”ì¶œ
        registry_goals = set()
        for model in registry_data.get("models", []):
            purpose = model.get("purpose", "")
            if "goal" in purpose.lower():
                registry_goals.add(purpose)

        sparql_goals = set()
        # SPARQLì—ì„œ goalType ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
        goal_matches = re.findall(r'goalType\s*==?\s*["\']([^"\']+)["\']', sparql_rules, re.IGNORECASE)
        sparql_goals.update(goal_matches)

        pattern_goals = set(pattern_rules.get("goal_types", set()))

        # ì°¨ì´ì  í™•ì¸
        all_goals = registry_goals | sparql_goals | pattern_goals

        for goal in all_goals:
            sources = []
            if goal in registry_goals:
                sources.append("registry")
            if goal in sparql_goals:
                sources.append("sparql")
            if goal in pattern_goals:
                sources.append("patterns")

            if len(sources) != 3:
                missing = {"registry", "sparql", "patterns"} - set(sources)
                self.issues.append({
                    "type": "warning",
                    "category": "goal_type_inconsistency",
                    "message": f"Goal type '{goal}' missing from: {', '.join(missing)}",
                    "file": "multiple",
                    "goal": goal,
                    "present_in": sources,
                    "missing_from": list(missing)
                })

    def _check_model_purpose_mapping(self,
                                    registry_data: Dict[str, Any],
                                    sparql_rules: str) -> None:
        """ëª¨ë¸ purpose ë§¤í•‘ í™•ì¸"""
        registry_purposes = set()
        for model in registry_data.get("models", []):
            purpose = model.get("purpose")
            if purpose:
                registry_purposes.add(purpose)

        # SPARQLì—ì„œ purpose ì¶”ì¶œ
        sparql_purposes = set()
        purpose_matches = re.findall(r'purpose\s*==?\s*["\']([^"\']+)["\']', sparql_rules, re.IGNORECASE)
        sparql_purposes.update(purpose_matches)

        # purpose ë¶ˆì¼ì¹˜ í™•ì¸
        registry_only = registry_purposes - sparql_purposes
        sparql_only = sparql_purposes - registry_purposes

        if registry_only:
            self.issues.append({
                "type": "warning",
                "category": "purpose_mapping",
                "message": f"Purposes in registry but not in SPARQL: {registry_only}",
                "file": "config/rules.sparql"
            })

        if sparql_only:
            self.issues.append({
                "type": "warning",
                "category": "purpose_mapping",
                "message": f"Purposes in SPARQL but not in registry: {sparql_only}",
                "file": "config/model_registry.json"
            })

    def _check_model_registry_completeness(self, registry_data: Dict[str, Any]) -> None:
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì™„ì„±ë„ í™•ì¸"""
        required_fields = ["modelId", "purpose", "version", "metaDataFile"]
        optional_fields = ["description", "capabilities", "inputParameters", "outputSchema", "performance", "container"]

        for model in registry_data.get("models", []):
            model_id = model.get("modelId", "unknown")

            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            for field in required_fields:
                if field not in model or not model[field]:
                    self.issues.append({
                        "type": "error",
                        "category": "incomplete_model",
                        "message": f"Model '{model_id}' missing required field: {field}",
                        "file": "config/model_registry.json",
                        "model": model_id,
                        "field": field
                    })

            # metaDataFile ì¡´ì¬ í™•ì¸
            metadata_file = model.get("metaDataFile")
            if metadata_file:
                metadata_path = self.base_dir / metadata_file
                if not metadata_path.exists():
                    self.issues.append({
                        "type": "warning",
                        "category": "missing_metadata",
                        "message": f"Metadata file not found for model '{model_id}': {metadata_file}",
                        "file": metadata_file,
                        "model": model_id
                    })

    def _check_ontology_action_sequences(self,
                                        ontology_data: Optional[Graph],
                                        pattern_rules: Dict[str, Any]) -> None:
        """ì˜¨í†¨ë¡œì§€ ì•¡ì…˜ ì‹œí€€ìŠ¤ í™•ì¸"""
        if not ontology_data:
            return

        # hasActionSequence ê´€ê³„ í™•ì¸
        query = """
        PREFIX ex: <http://example.com/ontology#>
        SELECT ?goal ?actionSeq WHERE {
            ?goal ex:hasActionSequence ?actionSeq .
        }
        """

        try:
            results = list(ontology_data.query(query))
            ontology_goals = {str(result.goal).split('#')[-1] for result in results}

            pattern_goals = set(pattern_rules.get("goal_types", set()))

            # íŒ¨í„´ì—ëŠ” ìˆì§€ë§Œ ì˜¨í†¨ë¡œì§€ì— ì•¡ì…˜ ì‹œí€€ìŠ¤ê°€ ì—†ëŠ” Goal
            missing_actions = pattern_goals - ontology_goals
            if missing_actions:
                self.issues.append({
                    "type": "warning",
                    "category": "missing_action_sequence",
                    "message": f"Goals without action sequences in ontology: {missing_actions}",
                    "file": "config/ontology.owl",
                    "goals": list(missing_actions)
                })

        except Exception as e:
            self.issues.append({
                "type": "warning",
                "category": "ontology_query",
                "message": f"Failed to query ontology for action sequences: {e}",
                "file": "config/ontology.owl"
            })

    def _check_pipeline_stage_consistency(self, pattern_rules: Dict[str, Any]) -> None:
        """íŒŒì´í”„ë¼ì¸ ìŠ¤í…Œì´ì§€ ì¼ê´€ì„± í™•ì¸"""
        # ì¼ë°˜ì ì¸ ìŠ¤í…Œì´ì§€ ì •ì˜
        known_stages = {
            "aasQuery", "dataFiltering", "swrlSelection",
            "yamlBinding", "simulation", "modelSelection"
        }

        # íŒ¨í„´ íŒŒì¼ì—ì„œ ìŠ¤í…Œì´ì§€ ì •ë³´ í™•ì¸ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
        # í˜„ì¬ëŠ” ê¸°ë³¸ì ì¸ ê²€ì¦ë§Œ ìˆ˜í–‰

        for goal_type in pattern_rules.get("goal_types", set()):
            if "predict" in goal_type.lower():
                # ì˜ˆì¸¡ ê´€ë ¨ Goalì€ ëª¨ë¸ ì„ íƒì´ í•„ìš”
                expected_stages = ["swrlSelection", "yamlBinding", "simulation"]
            else:
                # ê¸°ë³¸ Goalì€ AAS ì¿¼ë¦¬
                expected_stages = ["aasQuery", "dataFiltering"]

            # ì‹¤ì œ ê²€ì¦ ë¡œì§ì€ ë” ë³µì¡í•´ì•¼ í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ í™•ì¸ë§Œ
            pass

    def _generate_report(self) -> Dict[str, Any]:
        """ê²€ì‚¬ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        issues_by_type = {"critical": [], "error": [], "warning": []}
        issues_by_category = {}

        for issue in self.issues:
            issue_type = issue.get("type", "warning")
            issues_by_type[issue_type].append(issue)

            category = issue.get("category", "unknown")
            if category not in issues_by_category:
                issues_by_category[category] = []
            issues_by_category[category].append(issue)

        total_issues = len(self.issues)
        critical_count = len(issues_by_type["critical"])
        error_count = len(issues_by_type["error"])
        warning_count = len(issues_by_type["warning"])

        # ìƒíƒœ ê²°ì •
        if critical_count > 0:
            status = "CRITICAL"
        elif error_count > 0:
            status = "ERROR"
        elif warning_count > 0:
            status = "WARNING"
        else:
            status = "OK"

        return {
            "status": status,
            "summary": {
                "total_issues": total_issues,
                "critical": critical_count,
                "error": error_count,
                "warning": warning_count
            },
            "issues_by_type": issues_by_type,
            "issues_by_category": issues_by_category,
            "all_issues": self.issues
        }

    def print_report(self, report: Dict[str, Any]) -> None:
        """ë¦¬í¬íŠ¸ ì¶œë ¥"""
        status = report["status"]
        summary = report["summary"]

        status_emoji = {
            "OK": "âœ…",
            "WARNING": "âš ï¸",
            "ERROR": "âŒ",
            "CRITICAL": "ğŸš¨"
        }

        print(f"\n{status_emoji.get(status, 'â“')} Registry Consistency Check: {status}")
        print("=" * 50)

        if summary["total_issues"] == 0:
            print("ğŸ‰ ëª¨ë“  ì„¤ì • íŒŒì¼ì´ ì¼ê´€ì„± ìˆê²Œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
            return

        print(f"ğŸ“Š ì´ {summary['total_issues']}ê°œ ë¬¸ì œ ë°œê²¬:")
        print(f"   ğŸš¨ Critical: {summary['critical']}")
        print(f"   âŒ Error: {summary['error']}")
        print(f"   âš ï¸  Warning: {summary['warning']}")

        # ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½
        print(f"\nğŸ“‚ ë¬¸ì œ ì¹´í…Œê³ ë¦¬:")
        for category, issues in report["issues_by_category"].items():
            print(f"   â€¢ {category}: {len(issues)}ê°œ")

        # ìƒì„¸ ë¬¸ì œ ëª©ë¡
        print(f"\nğŸ“‹ ìƒì„¸ ë¬¸ì œ ëª©ë¡:")
        for issue in report["all_issues"]:
            emoji = {"critical": "ğŸš¨", "error": "âŒ", "warning": "âš ï¸"}.get(issue["type"], "â“")
            print(f"   {emoji} [{issue['category']}] {issue['message']}")
            print(f"      ğŸ“ File: {issue['file']}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” Registry Consistency Checker")
    print("=" * 50)

    checker = RegistryChecker()
    report = checker.check_all()
    checker.print_report(report)

    # JSON ë¦¬í¬íŠ¸ ì €ì¥
    output_dir = Path("querygoal/output")
    output_dir.mkdir(parents=True, exist_ok=True)

    report_file = output_dir / "consistency_check_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥ë¨: {report_file}")

    return report["status"] == "OK"


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)