# execution_engine/agent_refactored.py
"""
ë¦¬íŒ©í† ë§ëœ Agent ëª¨ë“ˆ - Mockê³¼ Standard AAS ì„œë²„ ëª¨ë‘ ì§€ì›
Mock ì„œë²„ì™€ì˜ ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ í‘œì¤€ ì„œë²„ ì§€ì› ì¶”ê°€
"""
import requests, sys, time, json, uuid, base64
from pathlib import Path
from typing import Dict, Any, Optional
from kubernetes import client, config as k8s_config

sys.path.append(str(Path(__file__).resolve().parents[1]))
from config import (
    AAS_SERVER_URL, 
    AAS_SERVER_IP, 
    AAS_SERVER_PORT, 
    AAS_SERVER_TYPE,
    USE_STANDARD_SERVER
)

# í‘œì¤€ ì„œë²„ë¥¼ ì‚¬ìš©í•  ê²½ìš°ì—ë§Œ AASQueryClient ìž„í¬íŠ¸
if USE_STANDARD_SERVER:
    from aas_query_client import AASQueryClient

# --- í•¸ë“¤ëŸ¬ í´ëž˜ìŠ¤ë“¤ ---

class AASQueryHandler:
    """
    AAS ì„œë²„ì— ë°ì´í„°ë¥¼ ìš”ì²­í•˜ëŠ” í•¸ë“¤ëŸ¬
    Mockê³¼ Standard ì„œë²„ ëª¨ë‘ ì§€ì›
    """
    def __init__(self):
        self.server_type = AAS_SERVER_TYPE
        
        if USE_STANDARD_SERVER:
            # í‘œì¤€ ì„œë²„ ì‚¬ìš© ì‹œ AASQueryClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.client = AASQueryClient(AAS_SERVER_IP, AAS_SERVER_PORT)
            print(f"ðŸ”„ AASQueryHandler: Using STANDARD server client")
        else:
            # Mock ì„œë²„ ì‚¬ìš© ì‹œ ê¸°ì¡´ ë°©ì‹ ìœ ì§€
            self.client = None
            print(f"ðŸ“¦ AASQueryHandler: Using MOCK server (direct HTTP)")
    
    def _to_base64url(self, s: str) -> str:
        """Base64 URL ì¸ì½”ë”© (Mock ì„œë²„ìš©)"""
        return base64.urlsafe_b64encode(s.encode()).decode().rstrip("=")
    
    def _query_mock_server(self, target_sm_id: str) -> Dict[str, Any]:
        """Mock ì„œë²„ì— ì§ì ‘ ì¿¼ë¦¬ (ê¸°ì¡´ ë¡œì§)"""
        b64id = self._to_base64url(target_sm_id)
        url = f"{AAS_SERVER_URL}/submodels/{b64id}"
        
        print(f"INFO: Requesting from MOCK server: {url}")
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.json()
    
    def _query_standard_server(self, target_sm_id: str) -> Dict[str, Any]:
        """í‘œì¤€ ì„œë²„ì— AASQueryClientë¥¼ í†µí•´ ì¿¼ë¦¬"""
        print(f"INFO: Requesting from STANDARD server: {target_sm_id}")
        
        try:
            # AASQueryClientì˜ get_submodel_by_id ë©”ì†Œë“œ ì‚¬ìš©
            result = self.client.get_submodel_by_id(target_sm_id)
            if result:
                return result
            else:
                raise ValueError(f"Submodel {target_sm_id} not found on standard server")
        except Exception as e:
            print(f"ERROR: Standard server query failed: {e}")
            raise
    
    def execute(self, step_details: dict, context: dict) -> dict:
        params = step_details.get('params', {})
        goal = params.get('goal')
        action_id = step_details.get('action_id')
        
        # ActionFetchAllMachineData ê°™ì€ ë³µí•© ì¡°íšŒë¥¼ ìœ„í•œ ë¡œì§
        if action_id == 'ActionFetchAllMachineData':
            print("INFO: Simulating fetch of all machine data.")
            target_sm_id = "urn:factory:submodel:capability:cnc-01"
        else:
            target_sm_id = step_details.get('target_submodel_id')
            if not target_sm_id:
                if goal == 'track_product_position':
                    product_id = params.get('product_id')
                    if not product_id:
                        raise ValueError("product_id is required for track_product_position")
                    target_sm_id = f"urn:factory:submodel:tracking_data:{product_id.lower()}"
                elif goal == 'detect_anomaly_for_product':
                    target_machine = params.get('target_machine')
                    if not target_machine:
                        raise ValueError("target_machine is required for detect_anomaly_for_product")
                    target_sm_id = f"urn:factory:submodel:sensor_data:{target_machine.lower()}"
                else:
                    raise ValueError(f"Cannot determine target for goal: {goal}")
        
        # ì„œë²„ íƒ€ìž…ì— ë”°ë¼ ë‹¤ë¥¸ ì¿¼ë¦¬ ë°©ì‹ ì‚¬ìš©
        if USE_STANDARD_SERVER:
            return self._query_standard_server(target_sm_id)
        else:
            return self._query_mock_server(target_sm_id)

class DataFilteringHandler:
    """AASì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ DSL ì¡°ê±´ì— ë§žê²Œ í•„í„°ë§í•˜ê±°ë‚˜ ê°€ê³µí•˜ëŠ” í•¸ë“¤ëŸ¬"""
    
    def _parse_value(self, data: Any) -> Any:
        """
        ì„œë²„ ì‘ë‹µì˜ value í•„ë“œë¥¼ íŒŒì‹±
        Mockê³¼ Standard ì„œë²„ì˜ ë‹¤ë¥¸ ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
        """
        if isinstance(data, dict):
            # submodelElementsê°€ ìžˆëŠ” ê²½ìš° (í‘œì¤€ í˜•ì‹)
            if 'submodelElements' in data:
                elements = data.get('submodelElements', [])
                if elements and len(elements) > 0:
                    value = elements[0].get('value')
                    # valueê°€ ë¬¸ìžì—´ì´ë©´ JSON íŒŒì‹± ì‹œë„
                    if isinstance(value, str):
                        try:
                            return json.loads(value)
                        except json.JSONDecodeError:
                            return value
                    return value
            # ì§ì ‘ valueê°€ ìžˆëŠ” ê²½ìš°
            elif 'value' in data:
                value = data.get('value')
                if isinstance(value, str):
                    try:
                        return json.loads(value)
                    except json.JSONDecodeError:
                        return value
                return value
        return data
    
    def execute(self, step_details: dict, context: dict) -> dict:
        params = step_details.get('params', {})
        goal = params.get('goal')
        
        # Goal 1: ì‹¤íŒ¨í•œ ëƒ‰ê° Job í•„í„°ë§ ë¡œì§
        if goal == 'query_failed_jobs_with_cooling':
            data_to_filter = None
            for key, value in context.items():
                if 'ActionFetchJobLog' in key:
                    data_to_filter = self._parse_value(value)
                    break
            
            if data_to_filter is None:
                raise ValueError("Could not find data from previous step for Goal 1.")
            
            # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if not isinstance(data_to_filter, list):
                data_to_filter = [data_to_filter] if data_to_filter else []

            request_date = params.get('date')
            filtered_jobs = [
                job for job in data_to_filter
                if job.get('date') == request_date
                and job.get('status') == 'FAILED'
                and 'cooling' in job.get('process_steps', [])
            ]
            return {"final_result": filtered_jobs}
        
        # Goal 4: ì œí’ˆ ìœ„ì¹˜ ì¶”ì  ë¡œì§
        elif goal == 'track_product_position':
            tracking_data = None
            print(f"DEBUG: Processing Goal 4, context keys: {list(context.keys())}")
            
            for key, value in context.items():
                if 'ActionFetchTrackingData' in key:
                    print(f"DEBUG: Found tracking data in {key}")
                    print(f"DEBUG: Value type: {type(value)}, has submodelElements: {'submodelElements' in value if isinstance(value, dict) else False}")
                    
                    # í‘œì¤€ ì„œë²„ì˜ ê²½ìš° ì§ì ‘ ì‚¬ìš©, Mockì˜ ê²½ìš° íŒŒì‹±
                    if isinstance(value, dict) and 'submodelElements' in value:
                        # í‘œì¤€ ì„œë²„ í˜•ì‹ - submodelElementsì—ì„œ ë°ì´í„° ì¶”ì¶œ
                        elements = value.get('submodelElements', [])
                        tracking_info = {}
                        for element in elements:
                            id_short = element.get('idShort')
                            elem_value = element.get('value')
                            if id_short and elem_value:
                                tracking_info[id_short] = elem_value
                        tracking_data = tracking_info
                        print(f"DEBUG: Extracted tracking_info from standard format: {tracking_info}")
                    else:
                        # Mock ì„œë²„ í˜•ì‹ - _parse_value ì‚¬ìš©
                        tracking_data = self._parse_value(value)
                        print(f"DEBUG: Parsed value from mock format: {tracking_data}")
                    break
            
            if tracking_data is None:
                print(f"ERROR: No tracking data found in context: {context}")
                raise ValueError("Could not find tracking data from previous step for Goal 4.")
            
            print(f"DEBUG: Returning final_result: {tracking_data}")
            return {"final_result": tracking_data}
        
        # ì–´ë–¤ ì¡°ê±´ì—ë„ í•´ë‹¹í•˜ì§€ ì•Šì„ ê²½ìš°
        return {"final_result": "No applicable filter or processing logic for this goal."}

class SimulationInputHandler:
    """ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ë°ì´í„°ë¥¼ ì¡°í•©í•˜ì—¬ ì‹œë®¬ë ˆì´í„° ìž…ë ¥ íŒŒì¼ì„ ìƒì„±í•˜ëŠ” í•¸ë“¤ëŸ¬"""
    def execute(self, step_details: dict, context: dict) -> dict:
        params = step_details.get('params', {})
        job_id = str(uuid.uuid4())
        
        # ê³ ì •ëœ ê²½ë¡œ ì‚¬ìš©
        shared_dir = Path("/data")
        current_dir = shared_dir / "current"
        current_dir.mkdir(parents=True, exist_ok=True)
        
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì´ì „ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼ ìˆ˜ì§‘
        input_data = {
            "process_spec": context.get("step_1_ActionFetchProductSpec", {}),
            "machine_data": context.get("step_2_ActionFetchAllMachineData", {}),
            "order": params,
            "job_id": job_id
        }

        # ê³ ì • ê²½ë¡œì— ìž…ë ¥ íŒŒì¼ ìž‘ì„±
        input_file_path = current_dir / "simulation_inputs.json"
        with open(input_file_path, 'w') as f:
            json.dump(input_data, f, indent=2)

        print(f"INFO: Created simulation input file at {input_file_path} (job_id: {job_id})")
        return {"simulation_job_id": job_id}

class K8sJobHandler:
    """ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì— ì‹œë®¬ë ˆì´í„° Jobì„ ìƒì„±í•˜ê³  ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ëŠ” í•¸ë“¤ëŸ¬"""
    def __init__(self):
        try: 
            k8s_config.load_incluster_config()
        except k8s_config.ConfigException: 
            k8s_config.load_kube_config()
        self.batch_v1 = client.BatchV1Api()
        self.core_v1 = client.CoreV1Api()
        self.namespace = "default"

    def execute(self, step_details: dict, context: dict) -> dict:
        sim_context = context.get("step_3_ActionAssembleSimulatorInputs", {})
        job_id = sim_context.get("simulation_job_id")
        if not job_id: 
            raise ValueError("Simulation Job ID not found in context.")
        
        job_name = f"simulator-job-{job_id[:6]}"
        
        # ê³µìœ  ë³¼ë¥¨(PVC)ì„ Jobì˜ Podì— ë§ˆìš´íŠ¸
        volume_mount = client.V1VolumeMount(
            name="shared-data-volume", 
            mount_path="/data"
        )
        volume = client.V1Volume(
            name="shared-data-volume",
            persistent_volume_claim=client.V1PersistentVolumeClaimVolumeSource(
                claim_name="factory-shared-pvc"
            )
        )

        container = client.V1Container(
            name="simulator", 
            image="simulator:latest", 
            image_pull_policy="Never",
            volume_mounts=[volume_mount]
        )
        pod_spec = client.V1PodSpec(
            restart_policy="Never", 
            containers=[container], 
            volumes=[volume]
        )
        pod_template = client.V1PodTemplateSpec(
            metadata=client.V1ObjectMeta(labels={"app": "simulator"}), 
            spec=pod_spec
        )
        job_spec = client.V1JobSpec(template=pod_template, backoff_limit=1)
        job = client.V1Job(
            api_version="batch/v1", 
            kind="Job", 
            metadata=client.V1ObjectMeta(name=job_name), 
            spec=job_spec
        )

        print(f"INFO: Creating Kubernetes Job: {job_name}")
        self.batch_v1.create_namespaced_job(body=job, namespace=self.namespace)

        print("INFO: Waiting for Job to complete...")
        job_completed = False
        while not job_completed:
            time.sleep(2)
            job_status = self.batch_v1.read_namespaced_job_status(
                name=job_name, 
                namespace=self.namespace
            )
            if job_status.status.succeeded is not None and job_status.status.succeeded >= 1:
                job_completed = True
        print("INFO: Job completed successfully.")

        # ë¡œê·¸ ìˆ˜ì§‘
        pod_label_selector = f"job-name={job_name}"
        pods_list = self.core_v1.list_namespaced_pod(
            namespace=self.namespace, 
            label_selector=pod_label_selector
        )
        if not pods_list.items:
            raise RuntimeError(f"Could not find completed pod for job {job_name}")
        pod_name = pods_list.items[0].metadata.name
        
        result = None
        for i in range(5):
            print(f"INFO: Attempting to fetch logs for pod {pod_name} (Attempt {i+1}/5)")
            time.sleep(1)
            pod_log = self.core_v1.read_namespaced_pod_log(
                name=pod_name, 
                namespace=self.namespace
            )
            
            if pod_log:
                for line in pod_log.split('\n'):
                    line = line.strip()
                    if line.startswith('{') and line.endswith('}'):
                        try:
                            result = json.loads(line)
                            print("INFO: Successfully fetched and parsed logs.")
                            break
                        except json.JSONDecodeError:
                            continue
                
                if result:
                    break

        if result is None:
            raise RuntimeError(f"Failed to retrieve valid JSON result from pod {pod_name}")

        self.batch_v1.delete_namespaced_job(
            name=job_name, 
            namespace=self.namespace, 
            body=client.V1DeleteOptions()
        )
        print(f"INFO: Deleted Job: {job_name}")

        return {"final_result": result}

class AIModelHandler:
    def execute(self, step_details: dict, context: dict) -> dict:
        print("INFO: AI Model Handler (Not Implemented)")
        return {"result": "AI model placeholder"}

# --- ExecutionAgent ìµœì¢…ë³¸ ---
class ExecutionAgent:
    def __init__(self):
        print(f"ðŸš€ Initializing ExecutionAgent with {AAS_SERVER_TYPE} server")
        
        self.handlers = {
            "aas_query": AASQueryHandler(),
            "aas_query_multiple": AASQueryHandler(),
            "internal_processing": SimulationInputHandler(),
            "docker_run": K8sJobHandler(),
            "data_filtering": DataFilteringHandler(),
            "ai_model_inference": AIModelHandler(),
        }
        
    def run(self, plan: list, initial_params: dict) -> dict:
        execution_context = {}
        final_result = {}
        
        for i, step in enumerate(plan):
            step['params'] = initial_params

            action_type = step.get("type")
            handler = self.handlers.get(action_type)

            if not handler:
                print(f"WARN: No handler for action type '{action_type}', skipping.")
                continue
            
            try:
                step_result = handler.execute(step, execution_context)
                execution_context[f"step_{i+1}_{step['action_id']}"] = step_result

                if "final_result" in step_result:
                    final_result = step_result
                    
            except Exception as e:
                print(f"ERROR: Step {i+1} ({step.get('action_id')}) failed: {e}")
                raise

        return final_result if final_result else execution_context