"""
í•µì‹¬ ì„ íƒ ì—”ì§„: SPARQL ê¸°ë°˜ ëª¨ë¸ ì„ íƒ ë° ë©”íƒ€ë°ì´í„° í†µí•©
"""
import json
from datetime import datetime
from typing import Dict, Any, Optional, List
from rdflib import Graph, Namespace, URIRef, Literal, RDF
from rdflib.plugins.stores.memory import Memory

from .preprocessor import preprocess_query_goal, UnknownTokenError
from .schema_validator import validate_query_goal_schema, ValidationError


class SelectionEngineError(Exception):
    """ì„ íƒ ì—”ì§„ ê´€ë ¨ ì—ëŸ¬"""
    pass


class SelectionEngine:
    """SPARQL ê¸°ë°˜ ëª¨ë¸ ì„ íƒ ì—”ì§„"""

    def __init__(self, ontology_file: str = "config/ontology.owl",
                 rules_file: str = "config/rules.sparql",
                 model_registry_file: str = "config/model_registry.json"):
        """
        ì„ íƒ ì—”ì§„ ì´ˆê¸°í™”

        Args:
            ontology_file: RDF ì˜¨í†¨ë¡œì§€ íŒŒì¼ ê²½ë¡œ
            rules_file: SPARQL ê·œì¹™ íŒŒì¼ ê²½ë¡œ
            model_registry_file: ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ JSON íŒŒì¼ ê²½ë¡œ
        """
        self.ontology_file = ontology_file
        self.rules_file = rules_file
        self.model_registry_file = model_registry_file

        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
        self.ex = Namespace("http://example.com/ontology#")
        self.rdf = Namespace("http://www.w3.org/1999/02/22-rdf-syntax-ns#")

        # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ
        self.model_registry = self._load_model_registry()

    def select_model(self, query_goal_dict: Dict[str, Any]) -> Dict[str, Any]:
        """
        QueryGoalì— ëŒ€í•œ ëª¨ë¸ ì„ íƒ ìˆ˜í–‰

        Args:
            query_goal_dict: ì›ë³¸ QueryGoal ë”•ì…”ë„ˆë¦¬

        Returns:
            ì„ íƒëœ ëª¨ë¸ ì •ë³´ê°€ í¬í•¨ëœ í™•ì¥ QueryGoal

        Raises:
            SelectionEngineError: ì„ íƒ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒì‹œ
        """
        try:
            # Phase 1: ì „ì²˜ë¦¬ ë° ê²€ì¦
            processed_goal = preprocess_query_goal(query_goal_dict)
            validate_query_goal_schema(processed_goal)

            # Phase 2: SPARQL ì¶”ë¡ 
            graph = self._create_rdf_graph()
            self._add_query_goal_to_graph(processed_goal, graph)
            self._add_models_to_graph(graph)
            selected_model_id = self._execute_rules(graph, processed_goal["QueryGoal"]["goalType"])

            if not selected_model_id:
                raise SelectionEngineError(f"No matching model found for goalType: {processed_goal['QueryGoal']['goalType']}")

            # Phase 3: ë©”íƒ€ë°ì´í„° í†µí•©
            model_metadata = self._get_model_metadata(selected_model_id)
            provenance = self._generate_provenance(selected_model_id, processed_goal["QueryGoal"]["goalType"])

            # Phase 4: ìµœì¢… JSON ì¡°í•©
            return self._build_final_response(processed_goal, model_metadata, provenance)

        except (UnknownTokenError, ValidationError) as e:
            raise SelectionEngineError(f"Input validation failed: {e}")
        except Exception as e:
            raise SelectionEngineError(f"Selection process failed: {e}")

    def _load_model_registry(self) -> Dict[str, Any]:
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ JSON ë¡œë“œ"""
        try:
            with open(self.model_registry_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            raise SelectionEngineError(f"Model registry file not found: {self.model_registry_file}")
        except json.JSONDecodeError as e:
            raise SelectionEngineError(f"Invalid JSON in model registry: {e}")

    def _create_rdf_graph(self) -> Graph:
        """RDF ê·¸ë˜í”„ ìƒì„± ë° ì˜¨í†¨ë¡œì§€ ë¡œë“œ"""
        try:
            graph = Graph()
            graph.parse(self.ontology_file, format="xml")

            # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°”ì¸ë”©
            graph.bind("ex", self.ex)
            graph.bind("rdf", self.rdf)

            return graph
        except Exception as e:
            raise SelectionEngineError(f"Failed to load ontology: {e}")

    def _add_query_goal_to_graph(self, processed_goal: Dict[str, Any], graph: Graph) -> None:
        """QueryGoalì„ RDF ê·¸ë˜í”„ì— ì¶”ê°€"""
        goal_obj = processed_goal["QueryGoal"]

        # QueryGoal ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        goal_uri = URIRef(f"http://example.com/data#{goal_obj['goalId']}")
        graph.add((goal_uri, RDF.type, self.ex.QueryGoal))
        graph.add((goal_uri, self.ex.goalId, Literal(goal_obj["goalId"])))
        graph.add((goal_uri, self.ex.goalType, Literal(goal_obj["goalType"])))

        # Parameters ì¶”ê°€
        for i, param in enumerate(goal_obj.get("parameters", [])):
            param_uri = URIRef(f"http://example.com/data#{goal_obj['goalId']}_param_{i}")
            graph.add((param_uri, RDF.type, self.ex.Parameter))
            graph.add((param_uri, self.ex.parameterKey, Literal(param["key"])))
            graph.add((param_uri, self.ex.parameterValue, Literal(param["value"])))
            graph.add((goal_uri, self.ex.hasParameter, param_uri))

        # OutputSpec ì¶”ê°€
        for i, spec in enumerate(goal_obj.get("outputSpec", [])):
            spec_uri = URIRef(f"http://example.com/data#{goal_obj['goalId']}_output_{i}")
            graph.add((spec_uri, RDF.type, self.ex.OutputSpec))
            graph.add((spec_uri, self.ex.outputName, Literal(spec["name"])))
            graph.add((spec_uri, self.ex.outputDatatype, Literal(spec["datatype"])))
            graph.add((goal_uri, self.ex.hasOutputSpec, spec_uri))

    def _add_models_to_graph(self, graph: Graph) -> None:
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ ëª¨ë¸ë“¤ì„ RDF ê·¸ë˜í”„ì— ì¶”ê°€"""
        for model in self.model_registry.get("models", []):
            model_uri = URIRef(f"http://example.com/data#{model['modelId']}")
            graph.add((model_uri, RDF.type, self.ex.Model))
            graph.add((model_uri, self.ex.modelId, Literal(model["modelId"])))
            graph.add((model_uri, self.ex.purpose, Literal(model["purpose"])))
            graph.add((model_uri, self.ex.version, Literal(model["version"])))
            graph.add((model_uri, self.ex.metaDataFile, Literal(model["metaDataFile"])))

    def _execute_rules(self, graph: Graph, goal_type: str) -> Optional[str]:
        """SPARQL ê·œì¹™ ì‹¤í–‰ ë° ì„ íƒëœ ëª¨ë¸ ID ë°˜í™˜"""
        try:
            # SPARQL ê·œì¹™ íŒŒì¼ ë¡œë“œ
            with open(self.rules_file, "r", encoding="utf-8") as f:
                rules_content = f.read()

            # ê° ê·œì¹™ì„ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰ (INSERT ì¿¼ë¦¬ë“¤)
            # ì‹¤ì œë¡œëŠ” í•˜ë‚˜ì˜ í° íŒŒì¼ì—ì„œ ê°œë³„ ê·œì¹™ì„ ë¶„ë¦¬í•´ì•¼ í•˜ì§€ë§Œ,
            # ê°„ë‹¨íˆ ì „ì²´ ê·œì¹™ì„ ì‹¤í–‰

            # ê·œì¹™ì„ ê°œë³„ INSERT ë¬¸ìœ¼ë¡œ ë¶„ë¦¬
            insert_queries = self._parse_sparql_rules(rules_content)

            for query in insert_queries:
                try:
                    graph.update(query)
                except Exception as e:
                    print(f"Rule execution warning: {e}")

            # ì„ íƒëœ ëª¨ë¸ ì¡°íšŒ
            return self._query_selected_model(graph, goal_type)

        except FileNotFoundError:
            raise SelectionEngineError(f"Rules file not found: {self.rules_file}")
        except Exception as e:
            raise SelectionEngineError(f"Failed to execute rules: {e}")

    def _parse_sparql_rules(self, rules_content: str) -> List[str]:
        """SPARQL ê·œì¹™ íŒŒì¼ì—ì„œ ê°œë³„ INSERT ì¿¼ë¦¬ ë¶„ë¦¬"""
        # ê°„ë‹¨í•œ êµ¬í˜„: í•˜ë‚˜ì˜ í° UPDATE ì¿¼ë¦¬ë¡œ ì‹¤í–‰
        # PREFIX ì„ ì–¸ë“¤ ìˆ˜ì§‘
        prefixes = []
        insert_blocks = []

        lines = rules_content.split('\n')
        current_block = []
        collecting_insert = False

        for line in lines:
            line = line.strip()

            # ì£¼ì„ì´ë‚˜ ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
            if not line or line.startswith('#'):
                continue

            # PREFIX ìˆ˜ì§‘
            if line.startswith('PREFIX'):
                prefixes.append(line)
                continue

            # INSERT ë¸”ë¡ ì‹œì‘
            if line.startswith('INSERT'):
                if current_block:  # ì´ì „ ë¸”ë¡ ì €ì¥
                    insert_blocks.append('\n'.join(current_block))
                current_block = [line]
                collecting_insert = True
                continue

            if collecting_insert:
                current_block.append(line)

        # ë§ˆì§€ë§‰ ë¸”ë¡ ì €ì¥
        if current_block:
            insert_blocks.append('\n'.join(current_block))

        # ê° INSERT ë¸”ë¡ì„ ì™„ì „í•œ ì¿¼ë¦¬ë¡œ ë³€í™˜
        complete_queries = []
        prefix_block = '\n'.join(prefixes)

        for insert_block in insert_blocks:
            complete_query = prefix_block + '\n\n' + insert_block
            complete_queries.append(complete_query)

        return complete_queries

    def _query_selected_model(self, graph: Graph, goal_type: str) -> Optional[str]:
        """ì„ íƒëœ ëª¨ë¸ ID ì¡°íšŒ"""
        query = """
        PREFIX ex: <http://example.com/ontology#>

        SELECT ?modelId WHERE {
            ?goal ex:goalType ?goalType .
            ?goal ex:selectedModel ?model .
            ?model ex:modelId ?modelId .
            FILTER(?goalType = ?target_goal_type)
        }
        """

        results = graph.query(query, initBindings={'target_goal_type': Literal(goal_type)})

        for row in results:
            return str(row.modelId)

        return None

    def _get_model_metadata(self, model_id: str) -> Dict[str, Any]:
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        for model in self.model_registry.get("models", []):
            if model["modelId"] == model_id:
                return model

        raise SelectionEngineError(f"Model metadata not found for: {model_id}")

    def _generate_provenance(self, model_id: str, goal_type: str) -> Dict[str, Any]:
        """ì„ íƒ ê³¼ì •ì— ëŒ€í•œ provenance ì •ë³´ ìƒì„±"""
        return {
            "ruleName": f"SWRL:Goal2{model_id}",
            "engine": "Rule-based Module (SPARQL)",
            "evidence": {
                "matched": [
                    f"goalType=={goal_type}",
                    f"purpose=={self._get_model_metadata(model_id)['purpose']}"
                ]
            },
            "timestamp": datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"),
            "confidence": 1.0
        }

    def _build_final_response(self, processed_goal: Dict[str, Any],
                            model_metadata: Dict[str, Any],
                            provenance: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… ì‘ë‹µ JSON êµ¬ì„±"""
        
        # metaDataFileì´ NSGA2Model_sources.yamlì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë³€í™˜
        metadata_file = model_metadata.get("metaDataFile", "")
        if "NSGA2" in model_metadata.get("modelId", "") and metadata_file != "NSGA2Model_sources.yaml":
            # NSGA2 ëª¨ë¸ì€ í•­ìƒ í†µì¼ëœ íŒŒì¼ëª… ì‚¬ìš©
            metadata_file = "NSGA2Model_sources.yaml"
        
        # ì›ë³¸ QueryGoal ë³µì‚¬
        result = json.loads(json.dumps(processed_goal))

        # í™•ì¥ í•„ë“œ ì¶”ê°€
        result["QueryGoal"]["selectedModelRef"] = model_metadata["modelRef"]
        result["QueryGoal"]["selectedModel"] = {
            "modelId": model_metadata["modelId"],
            "MetaData": metadata_file,  # í†µì¼ëœ íŒŒì¼ëª… ì‚¬ìš©
            "outputs": [spec["name"] for spec in model_metadata.get("outputSchema", [])],
            "preconditions": {
                "units.time": "s",
                "runtime.freshness": "PT30S"
            },
            "container": model_metadata.get("container", {
                "image": "factory-nsga2:latest",
                "digest": "sha256:factory-nsga2-latest"
            }),
            "catalogVersion": model_metadata["version"],
            "frozenAt": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ")
        }
        result["QueryGoal"]["selectionProvenance"] = {
            "ruleName": provenance["ruleName"],
            "ruleVersion": "v1.0",
            "engine": provenance["engine"],
            "evidence": provenance["evidence"],
            "inputsHash": f"sha256:{hash(str(processed_goal))}",
            "timestamp": provenance["timestamp"],
            "notes": ""
        }

        return result


def main():
    """í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜ - output.json íŒŒì¼ ìƒì„±"""
    try:
        # user_input_clean.json ë¡œë“œ (ë˜ëŠ” user_input.json)
        input_files = ["user_input_clean.json", "user_input.json"]
        test_input = None
        input_file_used = None

        for input_file in input_files:
            try:
                with open(input_file, "r", encoding="utf-8") as f:
                    test_input = json.load(f)
                    input_file_used = input_file
                    break
            except FileNotFoundError:
                continue

        if test_input is None:
            raise FileNotFoundError("Neither user_input_clean.json nor user_input.json found")

        print("=== ëª¨ë¸ ì„ íƒ ì—”ì§„ í…ŒìŠ¤íŠ¸ ===")
        print(f"ì…ë ¥ íŒŒì¼: {input_file_used}")
        print("ì…ë ¥:")
        print(json.dumps(test_input, indent=2, ensure_ascii=False))

        # ì„ íƒ ì—”ì§„ ì‹¤í–‰
        engine = SelectionEngine()
        result = engine.select_model(test_input)

        # output.json íŒŒì¼ë¡œ ì €ì¥
        output_file = "output.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… ì„ íƒ ì™„ë£Œ! ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("\nğŸ“„ ì„ íƒëœ ëª¨ë¸ ì •ë³´:")
        print(f"   - ëª¨ë¸ ID: {result['QueryGoal']['selectedModel']['modelId']}")
        print(f"   - ëª©ì : {result['QueryGoal']['selectedModel']['purpose']}")
        print(f"   - ë²„ì „: {result['QueryGoal']['selectedModel']['version']}")
        print(f"   - ê·œì¹™: {result['QueryGoal']['selectionProvenance']['ruleName']}")

    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except SelectionEngineError as e:
        print(f"âŒ ì„ íƒ ì—”ì§„ ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()