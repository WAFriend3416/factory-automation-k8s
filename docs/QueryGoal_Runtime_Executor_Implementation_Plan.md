# QueryGoal Runtime Executor êµ¬í˜„ ê³„íš

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
- **ì‘ì„±ì¼**: 2025-09-29
- **ì°¸ê³  ë¬¸ì„œ**: `/Users/jsh/Desktop/aas-project/gemini-ver/docs/QueryGoal_Runtime_Integration_Plan.md`
- **ëª©ì **: QueryGoal íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ìƒì„±ëœ Goalì„ ì‹¤ì œ AAS ì„œë²„ì™€ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ì— ì—°ë™í•˜ëŠ” Runtime Executor êµ¬í˜„

## ğŸ¯ êµ¬í˜„ ëª©í‘œ

### í•µì‹¬ ë¹„ì „
ì™„ì„±ëœ QueryGoal ê°ì²´ë¥¼ ë°›ì•„ `metadata.pipelineStages` ìˆœì„œëŒ€ë¡œ ì‹¤ì œ ì‹¤í–‰í•˜ì—¬ ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” Production Runtime System êµ¬ì¶•

### ì£¼ìš” ëª©í‘œ
1. **QueryGoalExecutor êµ¬í˜„**: Stage-Gate ë°©ì‹ì˜ ì‹¤í–‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
2. **Goal3 íŠ¹í™” ìŠ¤í…Œì´ì§€**: swrlSelection â†’ yamlBinding â†’ simulation
3. **ê³µí†µ ëŸ°íƒ€ì„ ì»´í¬ë„ŒíŠ¸**: AAS Client, Manifest Parser, ì‘ì—… ë””ë ‰í„°ë¦¬ ê´€ë¦¬
4. **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: ë‹¤ë¥¸ Goal ìœ í˜•ì—ë„ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ì¡°

## ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„

### âœ… ê¸°ì¡´ êµ¬í˜„ ì™„ë£Œ ìƒíƒœ
```
Current QueryGoal Pipeline (ì™„ë£Œ):
â”œâ”€â”€ Pattern Matching â†’ Goal ìœ í˜• ì‹ë³„ âœ…
â”œâ”€â”€ Template Loading â†’ ê¸°ë³¸ êµ¬ì¡° ìƒì„± âœ…
â”œâ”€â”€ Parameter Filling â†’ íŒŒë¼ë¯¸í„° ë°”ì¸ë”© âœ…
â”œâ”€â”€ Action Plan Resolution â†’ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ âœ…
â”œâ”€â”€ Model Selection â†’ AI/ML ëª¨ë¸ ì„ íƒ âœ…
â””â”€â”€ Validation â†’ í’ˆì§ˆ ê²€ì¦ âœ…

Result: QueryGoal JSON ê°ì²´ ìƒì„± ì™„ë£Œ
```

### ğŸ”„ Runtime Executor êµ¬í˜„ ëŒ€ìƒ
```
New Runtime Execution (êµ¬í˜„ í•„ìš”):
â”œâ”€â”€ QueryGoalExecutor ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ğŸ”„
â”œâ”€â”€ Stage í•¸ë“¤ëŸ¬ ì‹œìŠ¤í…œ ğŸ”„
â”œâ”€â”€ AAS ì„œë²„ ì—°ë™ í´ë¼ì´ì–¸íŠ¸ ğŸ”„
â”œâ”€â”€ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ í†µí•© ğŸ”„
â””â”€â”€ Stage-Gate ì„±ê³µ íŒì • ğŸ”„

Result: ì‹¤ì œ ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ì‘ì—… ìˆ˜í–‰
```

## ğŸ—ï¸ Runtime Executor ì•„í‚¤í…ì²˜

### ì „ì²´ ì‹¤í–‰ í”Œë¡œìš°
```mermaid
graph TD
    A[Completed QueryGoal] --> B[QueryGoalExecutor]
    B --> C{Pipeline Stages}

    C --> D[SwrlSelectionHandler]
    D --> E[Stage-Gate Check]
    E --> F[YamlBindingHandler]
    F --> G[Stage-Gate Check]
    G --> H[SimulationHandler]
    H --> I[Stage-Gate Check]

    I --> J[Final Result]

    D --> K[(Model Registry)]
    F --> L[(AAS Server)]
    H --> M[(Container Registry)]

    E --> N[Failure Recovery]
    G --> N
    I --> N
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°
```
querygoal/
â”œâ”€â”€ runtime/
â”‚   â”œâ”€â”€ executor.py              # QueryGoalExecutor ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”œâ”€â”€ base_handler.py      # ê¸°ë³¸ í•¸ë“¤ëŸ¬ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ swrl_selection_handler.py
â”‚   â”‚   â”œâ”€â”€ yaml_binding_handler.py
â”‚   â”‚   â””â”€â”€ simulation_handler.py
â”‚   â”œâ”€â”€ clients/
â”‚   â”‚   â”œâ”€â”€ aas_client.py        # AAS ì„œë²„ REST API í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â””â”€â”€ container_client.py   # Docker/K8s ì»¨í…Œì´ë„ˆ í´ë¼ì´ì–¸íŠ¸
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ manifest_parser.py   # YAML ë©”ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì„œ
â”‚   â”‚   â”œâ”€â”€ work_directory.py    # ì‹¤í–‰ë³„ ì‘ì—… ë””ë ‰í„°ë¦¬ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ stage_gate.py        # Stage-Gate ì„±ê³µ íŒì • ë¡œì§
â”‚   â””â”€â”€ exceptions.py            # Runtime ì˜ˆì™¸ í´ë˜ìŠ¤ë“¤
```

## ğŸ“‹ Phase 1: í•µì‹¬ Runtime Executor (ì£¼ 1-2)

### Task 1.1: QueryGoalExecutor ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° êµ¬í˜„ (2ì¼)

#### ë©”ì¸ ì‹¤í–‰ê¸°: `querygoal/runtime/executor.py`
```python
"""
QueryGoal Runtime Executor
ì™„ì„±ëœ QueryGoalì„ ì‹¤ì œ ì‹¤í–‰í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
"""
import asyncio
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from dataclasses import dataclass
from pathlib import Path

from ..pipeline.orchestrator import PipelineOrchestrator
from .handlers.base_handler import BaseHandler
from .handlers.swrl_selection_handler import SwrlSelectionHandler
from .handlers.yaml_binding_handler import YamlBindingHandler
from .handlers.simulation_handler import SimulationHandler
from .utils.work_directory import WorkDirectoryManager
from .utils.stage_gate import StageGateValidator
from .exceptions import (
    RuntimeExecutionError,
    StageExecutionError,
    StageGateFailureError
)

logger = logging.getLogger("querygoal.runtime")

@dataclass
class ExecutionContext:
    """ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì •ë³´"""
    goal_id: str
    goal_type: str
    work_directory: Path
    start_time: datetime
    pipeline_stages: List[str]
    current_stage: Optional[str] = None
    stage_results: Dict[str, Any] = None

    def __post_init__(self):
        if self.stage_results is None:
            self.stage_results = {}

class QueryGoalExecutor:
    """
    QueryGoal Runtime Executor
    ì™„ì„±ëœ QueryGoalì„ ë°›ì•„ ì‹¤ì œ ì‹¤í–‰ì„ ìˆ˜í–‰
    """

    def __init__(self):
        self.work_dir_manager = WorkDirectoryManager()
        self.stage_gate_validator = StageGateValidator()

        # Stage í•¸ë“¤ëŸ¬ ë§¤í•‘
        self.stage_handlers = {
            "swrlSelection": SwrlSelectionHandler(),
            "yamlBinding": YamlBindingHandler(),
            "simulation": SimulationHandler()
        }

        # Stage-Gate ì„±ê³µ ê¸°ì¤€
        self.stage_criteria = {
            "swrlSelection": {
                "success_criteria": lambda result: result.get("selectedModel") is not None
            },
            "yamlBinding": {
                "success_criteria": lambda result: result.get("success_rate", 0) >= 1.0
            },
            "simulation": {
                "success_criteria": lambda result: result.get("status") == "completed"
            }
        }

    async def execute_querygoal(self, querygoal: Dict[str, Any]) -> Dict[str, Any]:
        """
        QueryGoal ì‹¤í–‰ ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
        """
        start_time = datetime.utcnow()
        qg = querygoal["QueryGoal"]

        try:
            # ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
            context = ExecutionContext(
                goal_id=qg["goalId"],
                goal_type=qg["goalType"],
                work_directory=self.work_dir_manager.create_work_directory(qg["goalId"]),
                start_time=start_time,
                pipeline_stages=qg["metadata"]["pipelineStages"]
            )

            logger.info(f"ğŸš€ Starting QueryGoal execution for {context.goal_id}")
            logger.info(f"ğŸ“‹ Pipeline stages: {context.pipeline_stages}")

            # Stageë³„ ìˆœì°¨ ì‹¤í–‰
            execution_log = {
                "goalId": context.goal_id,
                "startTime": start_time.isoformat(),
                "stages": [],
                "status": "in_progress"
            }

            for stage_name in context.pipeline_stages:
                context.current_stage = stage_name

                try:
                    # Stage ì‹¤í–‰
                    stage_result = await self._execute_stage(
                        stage_name, querygoal, context
                    )

                    # Stage-Gate ê²€ì¦
                    gate_result = self.stage_gate_validator.validate_stage(
                        stage_name, stage_result, self.stage_criteria
                    )

                    if not gate_result.passed:
                        raise StageGateFailureError(
                            f"Stage-Gate failed for {stage_name}: {gate_result.reason}"
                        )

                    # ì„±ê³µ ì‹œ ê²°ê³¼ ê¸°ë¡
                    context.stage_results[stage_name] = stage_result

                    execution_log["stages"].append({
                        "stage": stage_name,
                        "status": "completed",
                        "result": stage_result,
                        "gate_check": gate_result.__dict__,
                        "timestamp": datetime.utcnow().isoformat()
                    })

                    logger.info(f"âœ… Stage '{stage_name}' completed successfully")

                except Exception as e:
                    # Stage ì‹¤íŒ¨ ì²˜ë¦¬
                    error_info = {
                        "stage": stage_name,
                        "status": "failed",
                        "error": str(e),
                        "timestamp": datetime.utcnow().isoformat()
                    }

                    execution_log["stages"].append(error_info)
                    execution_log["status"] = "failed"
                    execution_log["failedStage"] = stage_name
                    execution_log["endTime"] = datetime.utcnow().isoformat()

                    logger.error(f"âŒ Stage '{stage_name}' failed: {e}")

                    raise RuntimeExecutionError(
                        f"QueryGoal execution failed at stage '{stage_name}': {e}"
                    ) from e

            # ì „ì²´ ì‹¤í–‰ ì„±ê³µ
            execution_log["status"] = "completed"
            execution_log["endTime"] = datetime.utcnow().isoformat()

            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            final_result = {
                "QueryGoal": qg,
                "executionLog": execution_log,
                "results": context.stage_results,
                "workDirectory": str(context.work_directory)
            }

            logger.info(f"ğŸ‰ QueryGoal {context.goal_id} executed successfully")
            return final_result

        except Exception as e:
            logger.error(f"ğŸ’¥ QueryGoal execution failed: {e}")

            # ì‹¤íŒ¨ ì‹œ ì •ë¦¬ ì‘ì—…
            if 'context' in locals():
                await self._cleanup_on_failure(context, str(e))

            raise RuntimeExecutionError(f"QueryGoal execution failed: {e}") from e

        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ì„±ê³µ/ì‹¤íŒ¨ ë¬´ê´€)
            if 'context' in locals():
                await self._cleanup_resources(context)

    async def _execute_stage(self,
                           stage_name: str,
                           querygoal: Dict[str, Any],
                           context: ExecutionContext) -> Dict[str, Any]:
        """ê°œë³„ Stage ì‹¤í–‰"""

        if stage_name not in self.stage_handlers:
            raise StageExecutionError(f"Unknown stage: {stage_name}")

        handler = self.stage_handlers[stage_name]

        logger.info(f"ğŸ“ Executing stage: {stage_name}")
        stage_start_time = datetime.utcnow()

        try:
            # Stage ì‹¤í–‰
            result = await handler.execute(querygoal, context)

            execution_time = (datetime.utcnow() - stage_start_time).total_seconds()

            # ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            result.update({
                "stage": stage_name,
                "executionTime": execution_time,
                "timestamp": datetime.utcnow().isoformat()
            })

            return result

        except Exception as e:
            execution_time = (datetime.utcnow() - stage_start_time).total_seconds()

            logger.error(f"Stage {stage_name} execution failed after {execution_time:.2f}s: {e}")

            raise StageExecutionError(
                f"Stage '{stage_name}' execution failed: {e}"
            ) from e

    async def _cleanup_on_failure(self, context: ExecutionContext, error_message: str):
        """ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì •ë¦¬ ì‘ì—…"""
        try:
            # ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥
            failure_log_path = context.work_directory / "failure.log"
            with open(failure_log_path, 'w') as f:
                f.write(f"Execution failed at: {datetime.utcnow().isoformat()}\n")
                f.write(f"Failed stage: {context.current_stage}\n")
                f.write(f"Error: {error_message}\n")
                f.write(f"Stage results: {context.stage_results}\n")

            logger.info(f"ğŸ’¾ Failure log saved to {failure_log_path}")

        except Exception as cleanup_error:
            logger.error(f"Failed to save failure log: {cleanup_error}")

    async def _cleanup_resources(self, context: ExecutionContext):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # í•„ìš”ì‹œ ì‘ì—… ë””ë ‰í„°ë¦¬ ì •ë¦¬ (ì„¤ì •ì— ë”°ë¼)
            # self.work_dir_manager.cleanup_work_directory(context.work_directory)

            logger.debug(f"ğŸ§¹ Resources cleaned up for {context.goal_id}")

        except Exception as cleanup_error:
            logger.warning(f"Resource cleanup warning: {cleanup_error}")

# Factory pattern for executor creation
def create_querygoal_executor() -> QueryGoalExecutor:
    """QueryGoalExecutor íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return QueryGoalExecutor()
```

#### Stage-Gate ê²€ì¦ ì‹œìŠ¤í…œ: `querygoal/runtime/utils/stage_gate.py`
```python
"""
Stage-Gate Validation System
ê° ë‹¨ê³„ì˜ ì„±ê³µ/ì‹¤íŒ¨ë¥¼ íŒì •í•˜ëŠ” ê²€ì¦ ë¡œì§
"""
import logging
from typing import Dict, Any, Callable
from dataclasses import dataclass

logger = logging.getLogger("querygoal.stage_gate")

@dataclass
class StageGateResult:
    """Stage-Gate ê²€ì¦ ê²°ê³¼"""
    stage_name: str
    passed: bool
    reason: str
    validation_details: Dict[str, Any]

class StageGateValidator:
    """Stage-Gate ê²€ì¦ê¸°"""

    def validate_stage(self,
                      stage_name: str,
                      stage_result: Dict[str, Any],
                      stage_criteria: Dict[str, Dict]) -> StageGateResult:
        """
        Stage ê²°ê³¼ë¥¼ ê¸°ì¤€ì— ë”°ë¼ ê²€ì¦
        """

        if stage_name not in stage_criteria:
            logger.warning(f"No criteria defined for stage: {stage_name}")
            return StageGateResult(
                stage_name=stage_name,
                passed=True,  # ê¸°ì¤€ì´ ì—†ìœ¼ë©´ í†µê³¼ë¡œ ì²˜ë¦¬
                reason="No validation criteria defined",
                validation_details={}
            )

        criteria = stage_criteria[stage_name]
        success_criteria = criteria["success_criteria"]

        try:
            # ì„±ê³µ ì¡°ê±´ ê²€ì¦
            if callable(success_criteria):
                passed = success_criteria(stage_result)
            else:
                # ê°„ë‹¨í•œ í‚¤-ê°’ ê²€ì¦
                passed = stage_result.get(success_criteria, False)

            validation_details = {
                "stage_result_keys": list(stage_result.keys()),
                "validation_applied": str(success_criteria),
                "result_sample": {k: str(v)[:100] for k, v in list(stage_result.items())[:3]}
            }

            if passed:
                return StageGateResult(
                    stage_name=stage_name,
                    passed=True,
                    reason="Stage criteria satisfied",
                    validation_details=validation_details
                )
            else:
                return StageGateResult(
                    stage_name=stage_name,
                    passed=False,
                    reason=f"Stage criteria not met: {success_criteria}",
                    validation_details=validation_details
                )

        except Exception as e:
            logger.error(f"Stage-Gate validation error for {stage_name}: {e}")
            return StageGateResult(
                stage_name=stage_name,
                passed=False,
                reason=f"Validation error: {e}",
                validation_details={"error": str(e)}
            )
```

### Task 1.2: Base Handler ë° ì˜ˆì™¸ ì‹œìŠ¤í…œ (1ì¼)

#### ê¸°ë³¸ í•¸ë“¤ëŸ¬: `querygoal/runtime/handlers/base_handler.py`
```python
"""
Base Handler for Runtime Stages
ëª¨ë“  Stage í•¸ë“¤ëŸ¬ì˜ ê¸°ë³¸ í´ë˜ìŠ¤
"""
import logging
from abc import ABC, abstractmethod
from typing import Dict, Any
from datetime import datetime

from ..executor import ExecutionContext

logger = logging.getLogger("querygoal.handlers")

class BaseHandler(ABC):
    """Stage í•¸ë“¤ëŸ¬ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.handler_name = self.__class__.__name__
        self.logger = logging.getLogger(f"querygoal.handlers.{self.handler_name}")

    @abstractmethod
    async def execute(self,
                     querygoal: Dict[str, Any],
                     context: ExecutionContext) -> Dict[str, Any]:
        """
        Stage ì‹¤í–‰ ë¡œì§ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)

        Args:
            querygoal: ì™„ì„±ëœ QueryGoal ê°ì²´
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            Stage ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        pass

    async def pre_execute(self,
                         querygoal: Dict[str, Any],
                         context: ExecutionContext):
        """ì‹¤í–‰ ì „ ê³µí†µ ì¤€ë¹„ ì‘ì—…"""
        self.logger.info(f"ğŸ”„ Starting {self.handler_name} for {context.goal_id}")

    async def post_execute(self,
                          result: Dict[str, Any],
                          context: ExecutionContext):
        """ì‹¤í–‰ í›„ ê³µí†µ ì •ë¦¬ ì‘ì—…"""
        self.logger.info(f"âœ… Completed {self.handler_name} for {context.goal_id}")

    def validate_prerequisites(self,
                              querygoal: Dict[str, Any],
                              context: ExecutionContext) -> bool:
        """ì‹¤í–‰ ì „ ì „ì œì¡°ê±´ ê²€ì¦"""
        # ê¸°ë³¸ì ì¸ QueryGoal êµ¬ì¡° ê²€ì¦
        qg = querygoal.get("QueryGoal", {})

        required_fields = ["goalId", "goalType", "metadata"]
        for field in required_fields:
            if field not in qg:
                self.logger.error(f"Missing required field in QueryGoal: {field}")
                return False

        return True

    def create_error_result(self, error_message: str, details: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ê²°ê³¼ ìƒì„±"""
        return {
            "status": "error",
            "error": error_message,
            "details": details or {},
            "handler": self.handler_name,
            "timestamp": datetime.utcnow().isoformat()
        }

    def create_success_result(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì„±ê³µ ê²°ê³¼ ìƒì„±"""
        return {
            "status": "success",
            "handler": self.handler_name,
            "timestamp": datetime.utcnow().isoformat(),
            **data
        }
```

#### ì˜ˆì™¸ í´ë˜ìŠ¤: `querygoal/runtime/exceptions.py`
```python
"""
Runtime Execution Exceptions
Runtime ì‹¤í–‰ ì¤‘ ë°œìƒí•˜ëŠ” ì˜ˆì™¸ë“¤
"""

class RuntimeExecutionError(Exception):
    """Runtime ì‹¤í–‰ ì‹¤íŒ¨"""
    pass

class StageExecutionError(RuntimeExecutionError):
    """Stage ì‹¤í–‰ ì‹¤íŒ¨"""
    pass

class StageGateFailureError(RuntimeExecutionError):
    """Stage-Gate ê²€ì¦ ì‹¤íŒ¨"""
    pass

class AASConnectionError(RuntimeExecutionError):
    """AAS ì„œë²„ ì—°ê²° ì‹¤íŒ¨"""
    pass

class SimulationExecutionError(RuntimeExecutionError):
    """ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨"""
    pass

class ManifestParsingError(RuntimeExecutionError):
    """ë©”ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨"""
    pass

class WorkDirectoryError(RuntimeExecutionError):
    """ì‘ì—… ë””ë ‰í„°ë¦¬ ì˜¤ë¥˜"""
    pass
```

## ğŸ“‹ Phase 2: Goal3 íŠ¹í™” Stage í•¸ë“¤ëŸ¬ (ì£¼ 3-4)

### Task 2.1: SWRL Selection Handler (2ì¼)

#### SWRL ì„ íƒ í•¸ë“¤ëŸ¬: `querygoal/runtime/handlers/swrl_selection_handler.py`
```python
"""
SWRL Selection Handler
Goal3ì˜ swrlSelection ë‹¨ê³„ë¥¼ ì²˜ë¦¬
"""
import asyncio
from typing import Dict, Any
from pathlib import Path

from .base_handler import BaseHandler
from ..executor import ExecutionContext
from ..exceptions import StageExecutionError
from ...pipeline.model_selector import ModelSelector

class SwrlSelectionHandler(BaseHandler):
    """SWRL ê¸°ë°˜ ëª¨ë¸ ì„ íƒ í•¸ë“¤ëŸ¬"""

    def __init__(self):
        super().__init__()
        self.model_selector = ModelSelector()

    async def execute(self,
                     querygoal: Dict[str, Any],
                     context: ExecutionContext) -> Dict[str, Any]:
        """SWRL Selection ì‹¤í–‰"""

        await self.pre_execute(querygoal, context)

        if not self.validate_prerequisites(querygoal, context):
            return self.create_error_result("Prerequisites validation failed")

        try:
            qg = querygoal["QueryGoal"]
            goal_type = qg["goalType"]

            # ì´ë¯¸ ì„ íƒëœ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
            selected_model = qg.get("selectedModel")
            if selected_model:
                self.logger.info(f"ğŸ“¦ Model already selected: {selected_model.get('modelId')}")

                # ë©”ë‹ˆí˜ìŠ¤íŠ¸ ê²½ë¡œ í™•ì¸
                manifest_path = await self._load_model_manifest(selected_model, context)

                result_data = {
                    "selectedModel": selected_model,
                    "manifestPath": str(manifest_path),
                    "selectionMethod": "pre_selected",
                    "modelStatus": "ready"
                }

                await self.post_execute(result_data, context)
                return self.create_success_result(result_data)

            else:
                # ìƒˆë¡œìš´ ëª¨ë¸ ì„ íƒ ìˆ˜í–‰
                self.logger.info(f"ğŸ” Performing model selection for {goal_type}")

                # ModelSelectorë¥¼ í†µí•œ ëª¨ë¸ ì„ íƒ
                updated_qg = self.model_selector.bind_model_to_querygoal(
                    querygoal, goal_type
                )

                selected_model = updated_qg["QueryGoal"].get("selectedModel")
                if not selected_model:
                    return self.create_error_result(
                        f"No suitable model found for {goal_type}"
                    )

                # ì„ íƒëœ ëª¨ë¸ì˜ ë©”ë‹ˆí˜ìŠ¤íŠ¸ ë¡œë“œ
                manifest_path = await self._load_model_manifest(selected_model, context)

                result_data = {
                    "selectedModel": selected_model,
                    "manifestPath": str(manifest_path),
                    "selectionMethod": "swrl_selection",
                    "modelStatus": "ready"
                }

                # QueryGoal ì—…ë°ì´íŠ¸
                querygoal["QueryGoal"]["selectedModel"] = selected_model

                await self.post_execute(result_data, context)
                return self.create_success_result(result_data)

        except Exception as e:
            self.logger.error(f"SWRL Selection failed: {e}")
            return self.create_error_result(
                f"SWRL Selection failed: {e}",
                {"goal_type": goal_type}
            )

    async def _load_model_manifest(self,
                                  selected_model: Dict[str, Any],
                                  context: ExecutionContext) -> Path:
        """ëª¨ë¸ ë©”ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ"""

        try:
            # ìµœìƒìœ„ ë ˆë²¨ì—ì„œ metaDataFile í™•ì¸ (metadata ì¤‘ì²© ì—†ìŒ)
            metadata_file = selected_model.get("metaDataFile")

            # MetaData í‚¤ ë³€í˜•ë„ í™•ì¸ (SWRL ì—”ì§„ì—ì„œ ë°˜í™˜ë  ìˆ˜ ìˆìŒ)
            if not metadata_file:
                metadata_file = selected_model.get("MetaData")

            if not metadata_file:
                raise StageExecutionError("Model metadata file not specified")

            # ë©”ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ê²°ì •
            if metadata_file.startswith("/"):
                # ì ˆëŒ€ ê²½ë¡œ
                manifest_path = Path(metadata_file)
            else:
                # ìƒëŒ€ ê²½ë¡œ - config ë””ë ‰í„°ë¦¬ì—ì„œ ì°¾ê¸°
                from pathlib import Path
                config_dir = Path(__file__).parent.parent.parent.parent / "config"
                manifest_path = config_dir / metadata_file

            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not manifest_path.exists():
                raise StageExecutionError(f"Manifest file not found: {manifest_path}")

            self.logger.info(f"ğŸ“‹ Loaded manifest: {manifest_path}")
            return manifest_path

        except Exception as e:
            raise StageExecutionError(f"Failed to load model manifest: {e}") from e

    def validate_prerequisites(self,
                              querygoal: Dict[str, Any],
                              context: ExecutionContext) -> bool:
        """SWRL Selection ì „ì œì¡°ê±´ ê²€ì¦"""

        if not super().validate_prerequisites(querygoal, context):
            return False

        qg = querygoal["QueryGoal"]

        # Goal3ì—ë§Œ ì ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        if not qg.get("goalType", "").startswith("goal3"):
            self.logger.error("SWRL Selection is only applicable to Goal3")
            return False

        return True
```

### Task 2.2: YAML Binding Handler (3ì¼)

#### YAML ë°”ì¸ë”© í•¸ë“¤ëŸ¬: `querygoal/runtime/handlers/yaml_binding_handler.py`
```python
"""
YAML Binding Handler
Goal3ì˜ yamlBinding ë‹¨ê³„ë¥¼ ì²˜ë¦¬ - AAS ì„œë²„ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ë° JSON íŒŒì¼ ìƒì„±
"""
import asyncio
import json
from typing import Dict, Any, List
from pathlib import Path

from .base_handler import BaseHandler
from ..executor import ExecutionContext
from ..clients.aas_client import AASClient
from ..utils.manifest_parser import ManifestParser
from ..exceptions import StageExecutionError, AASConnectionError

class YamlBindingHandler(BaseHandler):
    """YAML ë©”ë‹ˆí˜ìŠ¤íŠ¸ ê¸°ë°˜ ë°ì´í„° ë°”ì¸ë”© í•¸ë“¤ëŸ¬"""

    def __init__(self):
        super().__init__()
        self.aas_client = AASClient()
        self.manifest_parser = ManifestParser()

    async def execute(self,
                     querygoal: Dict[str, Any],
                     context: ExecutionContext) -> Dict[str, Any]:
        """YAML Binding ì‹¤í–‰"""

        await self.pre_execute(querygoal, context)

        if not self.validate_prerequisites(querygoal, context):
            return self.create_error_result("Prerequisites validation failed")

        try:
            qg = querygoal["QueryGoal"]

            # ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ë©”ë‹ˆí˜ìŠ¤íŠ¸ ê²½ë¡œ í™•ì¸
            manifest_path = context.stage_results.get("swrlSelection", {}).get("manifestPath")
            if not manifest_path:
                return self.create_error_result("Manifest path not found from previous stage")

            # ë©”ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì‹±
            self.logger.info(f"ğŸ“‹ Parsing manifest: {manifest_path}")
            manifest_data = await self.manifest_parser.parse_manifest(Path(manifest_path))

            # ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡ ì¶”ì¶œ
            data_sources = manifest_data.get("data_sources", [])
            if not data_sources:
                return self.create_error_result("No data sources found in manifest")

            # ì‘ì—… ë””ë ‰í„°ë¦¬ì— JSON íŒŒì¼ ìƒì„±
            json_files = {}
            success_count = 0

            for source in data_sources:
                try:
                    source_name = source["name"]
                    source_type = source["type"]

                    self.logger.info(f"ğŸ” Processing data source: {source_name}")

                    if source_type == "aas_property":
                        # AAS Propertyì—ì„œ ë°ì´í„° ìˆ˜ì§‘
                        json_data = await self._fetch_aas_property_data(source)

                    elif source_type == "aas_shell_collection":
                        # AAS Shell ì»¬ë ‰ì…˜ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ (machines.json)
                        json_data = await self._fetch_aas_shell_collection(source)

                    else:
                        raise StageExecutionError(f"Unknown data source type: {source_type}")

                    # JSON íŒŒì¼ ì €ì¥
                    json_file_path = context.work_directory / f"{source_name}.json"
                    with open(json_file_path, 'w', encoding='utf-8') as f:
                        json.dump(json_data, f, indent=2, ensure_ascii=False)

                    json_files[source_name] = {
                        "path": str(json_file_path),
                        "size": json_file_path.stat().st_size,
                        "record_count": len(json_data) if isinstance(json_data, list) else 1
                    }

                    success_count += 1
                    self.logger.info(f"âœ… Created {source_name}.json ({json_files[source_name]['record_count']} records)")

                except Exception as e:
                    self.logger.error(f"âŒ Failed to process {source.get('name', 'unknown')}: {e}")
                    json_files[source.get('name', 'unknown')] = {
                        "error": str(e)
                    }

            # ì„±ê³µë¥  ê³„ì‚°
            total_sources = len(data_sources)
            success_rate = success_count / total_sources if total_sources > 0 else 0

            result_data = {
                "manifestPath": manifest_path,
                "totalDataSources": total_sources,
                "successfulSources": success_count,
                "success_rate": success_rate,
                "jsonFiles": json_files,
                "workDirectory": str(context.work_directory)
            }

            await self.post_execute(result_data, context)
            return self.create_success_result(result_data)

        except Exception as e:
            self.logger.error(f"YAML Binding failed: {e}")
            return self.create_error_result(
                f"YAML Binding failed: {e}",
                {"work_directory": str(context.work_directory)}
            )

    async def _fetch_aas_property_data(self, source: Dict[str, Any]) -> List[Dict[str, Any]]:
        """AAS Propertyì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""

        submodel_id = source["config"]["submodel_id"]
        property_path = source["config"]["property_path"]

        try:
            # AAS í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•´ ë°ì´í„° ì¡°íšŒ
            property_data = await self.aas_client.get_submodel_property(
                submodel_id, property_path
            )

            # JSON í˜•íƒœë¡œ ë³€í™˜
            if isinstance(property_data, str):
                # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
                return json.loads(property_data)
            elif isinstance(property_data, (list, dict)):
                return property_data
            else:
                # ë‹¨ìˆœ ê°’ì¸ ê²½ìš° ë°°ì—´ë¡œ ë˜í•‘
                return [{"value": property_data}]

        except Exception as e:
            raise AASConnectionError(f"Failed to fetch AAS property {property_path}: {e}") from e

    async def _fetch_aas_shell_collection(self, source: Dict[str, Any]) -> List[Dict[str, Any]]:
        """AAS Shell ì»¬ë ‰ì…˜ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ (machines.json ìƒì„±ìš©)"""

        shell_filter = source["config"].get("shell_filter", {})
        combination_rules = source["config"].get("combination_rules", [])

        try:
            # AAS ì„œë²„ì—ì„œ ëª¨ë“  Shell ëª©ë¡ ì¡°íšŒ
            shells = await self.aas_client.list_shells()

            # í•„í„° ì ìš©
            filtered_shells = []
            for shell in shells:
                if self._matches_shell_filter(shell, shell_filter):
                    filtered_shells.append(shell)

            # ì¡°í•© ê·œì¹™ì— ë”°ë¼ ë°ì´í„° êµ¬ì¡° ìƒì„±
            combined_data = []
            for shell in filtered_shells:
                shell_data = await self._apply_combination_rules(shell, combination_rules)
                combined_data.append(shell_data)

            self.logger.info(f"ğŸ“¦ Collected {len(combined_data)} machine records from {len(shells)} shells")
            return combined_data

        except Exception as e:
            raise AASConnectionError(f"Failed to fetch AAS shell collection: {e}") from e

    def _matches_shell_filter(self, shell: Dict[str, Any], filter_config: Dict[str, Any]) -> bool:
        """Shellì´ í•„í„° ì¡°ê±´ì— ë§ëŠ”ì§€ í™•ì¸"""

        # ì˜ˆ: idShortê°€ íŠ¹ì • íŒ¨í„´ì— ë§ëŠ”ì§€ í™•ì¸
        if "id_pattern" in filter_config:
            shell_id = shell.get("idShort", "")
            pattern = filter_config["id_pattern"]
            if pattern not in shell_id:
                return False

        return True

    async def _apply_combination_rules(self, shell: Dict[str, Any], rules: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì¡°í•© ê·œì¹™ì„ ì ìš©í•˜ì—¬ ìµœì¢… ë°ì´í„° êµ¬ì¡° ìƒì„±"""

        result = {
            "shell_id": shell.get("idShort"),
            "shell_identification": shell.get("identification", {})
        }

        # ê° ê·œì¹™ì— ë”°ë¼ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘
        for rule in rules:
            rule_type = rule.get("type")

            if rule_type == "submodel_property":
                # íŠ¹ì • Submodelì˜ Property ê°’ ì¶”ê°€
                submodel_id = rule["submodel_id"]
                property_path = rule["property_path"]
                result_key = rule["result_key"]

                try:
                    property_value = await self.aas_client.get_submodel_property(
                        submodel_id, property_path, shell_id=shell.get("idShort")
                    )
                    result[result_key] = property_value

                except Exception as e:
                    self.logger.warning(f"Failed to get property {property_path} for shell {shell.get('idShort')}: {e}")
                    result[result_key] = None

        return result

    def validate_prerequisites(self,
                              querygoal: Dict[str, Any],
                              context: ExecutionContext) -> bool:
        """YAML Binding ì „ì œì¡°ê±´ ê²€ì¦"""

        if not super().validate_prerequisites(querygoal, context):
            return False

        # swrlSelection ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if "swrlSelection" not in context.stage_results:
            self.logger.error("swrlSelection stage must be completed first")
            return False

        return True
```

### Task 2.3: Simulation Handler (3ì¼)

#### ì‹œë®¬ë ˆì´ì…˜ í•¸ë“¤ëŸ¬: `querygoal/runtime/handlers/simulation_handler.py`
```python
"""
Simulation Handler
Goal3ì˜ simulation ë‹¨ê³„ë¥¼ ì²˜ë¦¬ - Docker/K8s ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
"""
import asyncio
import json
from typing import Dict, Any
from pathlib import Path

from .base_handler import BaseHandler
from ..executor import ExecutionContext
from ..clients.container_client import ContainerClient
from ..exceptions import SimulationExecutionError

class SimulationHandler(BaseHandler):
    """ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ í•¸ë“¤ëŸ¬"""

    def __init__(self):
        super().__init__()
        self.container_client = ContainerClient()

    async def execute(self,
                     querygoal: Dict[str, Any],
                     context: ExecutionContext) -> Dict[str, Any]:
        """Simulation ì‹¤í–‰"""

        await self.pre_execute(querygoal, context)

        if not self.validate_prerequisites(querygoal, context):
            return self.create_error_result("Prerequisites validation failed")

        try:
            qg = querygoal["QueryGoal"]
            selected_model = qg.get("selectedModel", {})

            # ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ (container.image êµ¬ì¡° ì‚¬ìš©)
            container_info = selected_model.get("container", {})
            container_image = container_info.get("image")

            if not container_image:
                return self.create_error_result("Container image not specified in selected model")

            # ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ JSON íŒŒì¼ë“¤ í™•ì¸
            yaml_binding_result = context.stage_results.get("yamlBinding", {})
            json_files = yaml_binding_result.get("jsonFiles", {})

            if not json_files:
                return self.create_error_result("No JSON files found from yamlBinding stage")

            # ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ ì¤€ë¹„
            simulation_input = await self._prepare_simulation_input(
                qg, json_files, context.work_directory
            )

            # ì»¨í…Œì´ë„ˆ ì‹¤í–‰
            self.logger.info(f"ğŸš€ Starting simulation with container: {container_image}")

            execution_result = await self.container_client.run_simulation(
                image=container_image,
                input_data=simulation_input,
                work_directory=context.work_directory,
                goal_id=context.goal_id
            )

            # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ íŒŒì‹±
            simulation_output = await self._parse_simulation_output(
                execution_result, context.work_directory
            )

            # QueryGoal outputs ì—…ë°ì´íŠ¸
            await self._update_querygoal_outputs(qg, simulation_output)

            result_data = {
                "containerImage": container_image,
                "executionId": execution_result.get("execution_id"),
                "status": "completed",
                "simulationOutput": simulation_output,
                "executionTime": execution_result.get("execution_time"),
                "containerLogs": execution_result.get("logs_path")
            }

            await self.post_execute(result_data, context)
            return self.create_success_result(result_data)

        except Exception as e:
            self.logger.error(f"Simulation execution failed: {e}")
            return self.create_error_result(
                f"Simulation execution failed: {e}",
                {"container_image": container_image if 'container_image' in locals() else None}
            )

    async def _prepare_simulation_input(self,
                                       qg: Dict[str, Any],
                                       json_files: Dict[str, Any],
                                       work_directory: Path) -> Dict[str, Any]:
        """ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""

        try:
            # QueryGoal íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            parameters = {}
            for param in qg.get("parameters", []):
                parameters[param["key"]] = param["value"]

            # JSON íŒŒì¼ ê²½ë¡œ ëª©ë¡ ìƒì„±
            data_files = {}
            for file_name, file_info in json_files.items():
                if "path" in file_info:  # ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ íŒŒì¼ë§Œ
                    data_files[file_name] = file_info["path"]

            simulation_input = {
                "goal_id": qg["goalId"],
                "goal_type": qg["goalType"],
                "parameters": parameters,
                "data_files": data_files,
                "work_directory": str(work_directory)
            }

            # ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ íŒŒì¼ ì €ì¥
            input_file = work_directory / "simulation_input.json"
            with open(input_file, 'w', encoding='utf-8') as f:
                json.dump(simulation_input, f, indent=2, ensure_ascii=False)

            self.logger.info(f"ğŸ“„ Simulation input prepared: {input_file}")
            return simulation_input

        except Exception as e:
            raise SimulationExecutionError(f"Failed to prepare simulation input: {e}") from e

    async def _parse_simulation_output(self,
                                      execution_result: Dict[str, Any],
                                      work_directory: Path) -> Dict[str, Any]:
        """ì‹œë®¬ë ˆì´ì…˜ ì¶œë ¥ ê²°ê³¼ íŒŒì‹±"""

        try:
            # ì‹œë®¬ë ˆì´ì…˜ ì¶œë ¥ íŒŒì¼ ì°¾ê¸°
            output_files = ["simulation_output.json", "goal3_result.json", "result.json"]

            simulation_output = None
            for output_file in output_files:
                output_path = work_directory / output_file
                if output_path.exists():
                    with open(output_path, 'r', encoding='utf-8') as f:
                        simulation_output = json.load(f)
                    break

            if simulation_output is None:
                # ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ê²°ê³¼ì—ì„œ ì§ì ‘ ì¶”ì¶œ
                simulation_output = execution_result.get("output", {})

            # Goal3 íŠ¹í™” ê²°ê³¼ êµ¬ì¡° í™•ì¸
            if "goal3_data" in simulation_output:
                goal3_data = simulation_output["goal3_data"]
                return {
                    "predicted_completion_time": goal3_data.get("predicted_completion_time"),
                    "confidence": goal3_data.get("confidence", 0.95),
                    "simulator_type": goal3_data.get("simulator_type", "NSGA-II"),
                    "detailed_results": goal3_data.get("detailed_results", {}),
                    "execution_metadata": simulation_output.get("execution_metadata", {})
                }
            else:
                # ê¸°ë³¸ êµ¬ì¡°
                return simulation_output

        except Exception as e:
            raise SimulationExecutionError(f"Failed to parse simulation output: {e}") from e

    async def _update_querygoal_outputs(self,
                                       qg: Dict[str, Any],
                                       simulation_output: Dict[str, Any]):
        """QueryGoal outputs í•„ë“œ ì—…ë°ì´íŠ¸ (Goal3 outputSpecì— ë§ì¶° ë§¤í•‘)"""

        try:
            if "outputs" not in qg:
                qg["outputs"] = {}

            # Goal3 outputSpecì— ë§ì¶° ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë§¤í•‘
            # parameter_filler.pyì˜ Goal3 outputSpec: estimatedTime, confidence, productionPlan, bottlenecks
            qg["outputs"].update({
                # predicted_completion_time â†’ estimatedTime ë§¤í•‘
                "estimatedTime": simulation_output.get("predicted_completion_time"),

                # confidenceëŠ” ë™ì¼í•œ í•„ë“œëª…
                "confidence": simulation_output.get("confidence"),

                # detailed_resultsë¥¼ productionPlanìœ¼ë¡œ ë§¤í•‘
                "productionPlan": simulation_output.get("detailed_results", {}),

                # bottlenecks í•„ë“œ ë§¤í•‘ (ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ì—ì„œ ì¶”ì¶œ ë˜ëŠ” ê¸°ë³¸ê°’)
                "bottlenecks": simulation_output.get("bottlenecks",
                                                   simulation_output.get("detailed_results", {}).get("bottlenecks", []))
            })

            # ì¶”ê°€ ì •ë³´ëŠ” ë¡œê¹…ë§Œ (outputSpecì— ì—†ëŠ” í•„ë“œë“¤)
            extra_fields = {
                "simulator_type": simulation_output.get("simulator_type"),
                "execution_timestamp": simulation_output.get("execution_metadata", {}).get("timestamp")
            }

            for field, value in extra_fields.items():
                if value:
                    self.logger.info(f"ğŸ“Š Additional simulation info - {field}: {value}")

            self.logger.info("ğŸ“¤ QueryGoal outputs updated with Goal3 outputSpec mapping")

        except Exception as e:
            self.logger.warning(f"Failed to update QueryGoal outputs: {e}")

    def validate_prerequisites(self,
                              querygoal: Dict[str, Any],
                              context: ExecutionContext) -> bool:
        """Simulation ì „ì œì¡°ê±´ ê²€ì¦"""

        if not super().validate_prerequisites(querygoal, context):
            return False

        # ì´ì „ ë‹¨ê³„ë“¤ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
        required_stages = ["swrlSelection", "yamlBinding"]
        for stage in required_stages:
            if stage not in context.stage_results:
                self.logger.error(f"Required stage '{stage}' must be completed first")
                return False

        # ì„ íƒëœ ëª¨ë¸ì— ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        qg = querygoal["QueryGoal"]
        selected_model = qg.get("selectedModel", {})
        container_info = selected_model.get("container", {})
        container_image = container_info.get("image")

        if not container_image:
            self.logger.error("Container image not specified in selected model")
            return False

        return True
```

## ğŸ“‹ Phase 3: ê³µí†µ Runtime ì»´í¬ë„ŒíŠ¸ (ì£¼ 5-6)

### Task 3.1: AAS Client (2ì¼)

#### AAS í´ë¼ì´ì–¸íŠ¸: `querygoal/runtime/clients/aas_client.py`
```python
"""
AAS Server REST API Client
AAS ì„œë²„ì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
"""
import asyncio
import httpx
import logging
from typing import Dict, Any, List, Optional
from urllib.parse import urljoin

from ..exceptions import AASConnectionError

logger = logging.getLogger("querygoal.aas_client")

class AASClient:
    """AAS ì„œë²„ REST API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, base_url: str = None, timeout: int = 30):
        # ì„¤ì •ì—ì„œ AAS ì„œë²„ URL ê°€ì ¸ì˜¤ê¸°
        if base_url is None:
            from config import AAS_SERVER_URL
            base_url = AAS_SERVER_URL

        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.client = None

    async def __aenter__(self):
        await self._ensure_client()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.client:
            await self.client.aclose()

    async def _ensure_client(self):
        """HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if self.client is None:
            self.client = httpx.AsyncClient(
                timeout=httpx.Timeout(self.timeout),
                limits=httpx.Limits(max_keepalive_connections=10, max_connections=50)
            )

    async def list_shells(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  AAS Shell ëª©ë¡ ì¡°íšŒ"""

        await self._ensure_client()

        try:
            url = urljoin(self.base_url, "/shells")

            response = await self.client.get(url)
            response.raise_for_status()

            shells_data = response.json()

            # AAS ì„œë²„ ì‘ë‹µ í˜•ì‹ì— ë”°ë¼ ì¡°ì •
            if isinstance(shells_data, dict):
                return shells_data.get("result", shells_data.get("shells", []))
            elif isinstance(shells_data, list):
                return shells_data
            else:
                return []

        except httpx.HTTPStatusError as e:
            raise AASConnectionError(f"HTTP error while listing shells: {e.response.status_code}") from e
        except Exception as e:
            raise AASConnectionError(f"Failed to list AAS shells: {e}") from e

    async def get_shell(self, shell_id: str) -> Dict[str, Any]:
        """íŠ¹ì • Shell ì •ë³´ ì¡°íšŒ"""

        await self._ensure_client()

        try:
            # Shell ID ì¸ì½”ë”© (í•„ìš”ì‹œ)
            encoded_shell_id = shell_id  # í•„ìš”í•˜ë©´ URL ì¸ì½”ë”©
            url = urljoin(self.base_url, f"/shells/{encoded_shell_id}")

            response = await self.client.get(url)
            response.raise_for_status()

            return response.json()

        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                raise AASConnectionError(f"Shell not found: {shell_id}") from e
            raise AASConnectionError(f"HTTP error while getting shell {shell_id}: {e.response.status_code}") from e
        except Exception as e:
            raise AASConnectionError(f"Failed to get shell {shell_id}: {e}") from e

    async def list_submodels(self, shell_id: str = None) -> List[Dict[str, Any]]:
        """Submodel ëª©ë¡ ì¡°íšŒ"""

        await self._ensure_client()

        try:
            if shell_id:
                # íŠ¹ì • Shellì˜ Submodel ëª©ë¡
                url = urljoin(self.base_url, f"/shells/{shell_id}/submodels")
            else:
                # ì „ì²´ Submodel ëª©ë¡
                url = urljoin(self.base_url, "/submodels")

            response = await self.client.get(url)
            response.raise_for_status()

            submodels_data = response.json()

            if isinstance(submodels_data, dict):
                return submodels_data.get("result", submodels_data.get("submodels", []))
            elif isinstance(submodels_data, list):
                return submodels_data
            else:
                return []

        except httpx.HTTPStatusError as e:
            raise AASConnectionError(f"HTTP error while listing submodels: {e.response.status_code}") from e
        except Exception as e:
            raise AASConnectionError(f"Failed to list submodels: {e}") from e

    async def get_submodel_property(self,
                                   submodel_id: str,
                                   property_path: str,
                                   shell_id: str = None) -> Any:
        """Submodelì˜ íŠ¹ì • Property ê°’ ì¡°íšŒ"""

        await self._ensure_client()

        try:
            # Property ê²½ë¡œ êµ¬ì„±
            if shell_id:
                url = urljoin(
                    self.base_url,
                    f"/shells/{shell_id}/submodels/{submodel_id}/submodel-elements/{property_path}/value"
                )
            else:
                url = urljoin(
                    self.base_url,
                    f"/submodels/{submodel_id}/submodel-elements/{property_path}/value"
                )

            response = await self.client.get(url)
            response.raise_for_status()

            # Content-Typeì— ë”°ë¼ ì‘ë‹µ ì²˜ë¦¬
            content_type = response.headers.get("content-type", "")

            if "application/json" in content_type:
                return response.json()
            else:
                return response.text

        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                raise AASConnectionError(
                    f"Property not found: {property_path} in submodel {submodel_id}"
                ) from e
            raise AASConnectionError(
                f"HTTP error while getting property {property_path}: {e.response.status_code}"
            ) from e
        except Exception as e:
            raise AASConnectionError(f"Failed to get property {property_path}: {e}") from e

    async def health_check(self) -> bool:
        """AAS ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸"""

        await self._ensure_client()

        try:
            # ê¸°ë³¸ì ì¸ ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¡œ ì—°ê²° í™•ì¸
            test_endpoints = ["/health", "/shells", "/"]

            for endpoint in test_endpoints:
                try:
                    url = urljoin(self.base_url, endpoint)
                    response = await self.client.get(url)

                    if response.status_code < 500:  # 500ëŒ€ ì—ëŸ¬ê°€ ì•„ë‹ˆë©´ ì—°ê²°ì€ ë¨
                        logger.info(f"âœ… AAS server is accessible at {self.base_url}")
                        return True

                except httpx.RequestError:
                    continue

            return False

        except Exception as e:
            logger.error(f"AAS health check failed: {e}")
            return False
```

### Task 3.2: Container Client ë° ê¸°íƒ€ ìœ í‹¸ë¦¬í‹° (2ì¼)

#### ì»¨í…Œì´ë„ˆ í´ë¼ì´ì–¸íŠ¸: `querygoal/runtime/clients/container_client.py`
```python
"""
Container Client
Docker/Kubernetes ì»¨í…Œì´ë„ˆ ì‹¤í–‰ì„ ë‹´ë‹¹
"""
import asyncio
import json
import logging
import subprocess
from typing import Dict, Any
from pathlib import Path
from datetime import datetime
import uuid

from ..exceptions import SimulationExecutionError

logger = logging.getLogger("querygoal.container_client")

class ContainerClient:
    """ì»¨í…Œì´ë„ˆ ì‹¤í–‰ í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, execution_mode: str = "docker"):
        self.execution_mode = execution_mode  # "docker" or "kubernetes"

    async def run_simulation(self,
                           image: str,
                           input_data: Dict[str, Any],
                           work_directory: Path,
                           goal_id: str) -> Dict[str, Any]:
        """ì‹œë®¬ë ˆì´ì…˜ ì»¨í…Œì´ë„ˆ ì‹¤í–‰"""

        execution_id = f"{goal_id}_{uuid.uuid4().hex[:8]}"
        start_time = datetime.utcnow()

        logger.info(f"ğŸš€ Starting simulation container: {image}")
        logger.info(f"ğŸ“‹ Execution ID: {execution_id}")

        try:
            if self.execution_mode == "docker":
                result = await self._run_docker_container(
                    image, input_data, work_directory, execution_id
                )
            elif self.execution_mode == "kubernetes":
                result = await self._run_kubernetes_job(
                    image, input_data, work_directory, execution_id
                )
            else:
                raise SimulationExecutionError(f"Unsupported execution mode: {self.execution_mode}")

            execution_time = (datetime.utcnow() - start_time).total_seconds()

            result.update({
                "execution_id": execution_id,
                "execution_time": execution_time,
                "start_time": start_time.isoformat(),
                "end_time": datetime.utcnow().isoformat()
            })

            logger.info(f"âœ… Simulation completed in {execution_time:.2f}s")
            return result

        except Exception as e:
            execution_time = (datetime.utcnow() - start_time).total_seconds()
            logger.error(f"âŒ Simulation failed after {execution_time:.2f}s: {e}")
            raise SimulationExecutionError(f"Container execution failed: {e}") from e

    async def _run_docker_container(self,
                                  image: str,
                                  input_data: Dict[str, Any],
                                  work_directory: Path,
                                  execution_id: str) -> Dict[str, Any]:
        """Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰"""

        try:
            # Docker ì‹¤í–‰ ëª…ë ¹ì–´ êµ¬ì„±
            docker_cmd = [
                "docker", "run",
                "--rm",  # ì»¨í…Œì´ë„ˆ ìë™ ì‚­ì œ
                "-v", f"{work_directory}:/workspace",  # ë³¼ë¥¨ ë§ˆìš´íŠ¸
                "--name", f"simulation-{execution_id}",
                image
            ]

            # í™˜ê²½ ë³€ìˆ˜ë¡œ ì…ë ¥ ë°ì´í„° ì „ë‹¬ (í•„ìš”ì‹œ)
            for key, value in input_data.get("parameters", {}).items():
                docker_cmd.extend(["-e", f"{key.upper()}={value}"])

            logger.info(f"ğŸ³ Docker command: {' '.join(docker_cmd)}")

            # ë¹„ë™ê¸° í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
            process = await asyncio.create_subprocess_exec(
                *docker_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=work_directory
            )

            stdout, stderr = await process.communicate()

            # ê²°ê³¼ ì €ì¥
            logs_file = work_directory / f"container_logs_{execution_id}.txt"
            with open(logs_file, 'w', encoding='utf-8') as f:
                f.write(f"=== STDOUT ===\n{stdout.decode('utf-8', errors='replace')}\n")
                f.write(f"=== STDERR ===\n{stderr.decode('utf-8', errors='replace')}\n")

            if process.returncode != 0:
                raise SimulationExecutionError(
                    f"Docker container failed with exit code {process.returncode}: "
                    f"{stderr.decode('utf-8', errors='replace')}"
                )

            # ì¶œë ¥ ê²°ê³¼ íŒŒì‹± ì‹œë„
            output_data = {}
            try:
                # JSON ì¶œë ¥ì´ ìˆëŠ”ì§€ í™•ì¸
                stdout_str = stdout.decode('utf-8', errors='replace')
                for line in stdout_str.split('\n'):
                    line = line.strip()
                    if line.startswith('{') and line.endswith('}'):
                        output_data = json.loads(line)
                        break
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡°
                output_data = {"raw_output": stdout.decode('utf-8', errors='replace')}

            return {
                "execution_mode": "docker",
                "container_image": image,
                "exit_code": process.returncode,
                "output": output_data,
                "logs_path": str(logs_file)
            }

        except Exception as e:
            raise SimulationExecutionError(f"Docker execution failed: {e}") from e

    async def _run_kubernetes_job(self,
                                image: str,
                                input_data: Dict[str, Any],
                                work_directory: Path,
                                execution_id: str) -> Dict[str, Any]:
        """Kubernetes Job ì‹¤í–‰"""

        try:
            # K8s Job ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±
            job_manifest = self._create_k8s_job_manifest(
                image, input_data, work_directory, execution_id
            )

            # Job ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
            job_file = work_directory / f"k8s_job_{execution_id}.yaml"
            with open(job_file, 'w', encoding='utf-8') as f:
                import yaml
                yaml.dump(job_manifest, f, default_flow_style=False)

            # kubectl apply
            apply_cmd = ["kubectl", "apply", "-f", str(job_file)]
            apply_process = await asyncio.create_subprocess_exec(
                *apply_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            apply_stdout, apply_stderr = await apply_process.communicate()

            if apply_process.returncode != 0:
                raise SimulationExecutionError(
                    f"kubectl apply failed: {apply_stderr.decode('utf-8', errors='replace')}"
                )

            job_name = f"simulation-{execution_id}"

            # Job ì™„ë£Œ ëŒ€ê¸°
            await self._wait_for_job_completion(job_name)

            # Job ë¡œê·¸ ìˆ˜ì§‘
            logs = await self._get_job_logs(job_name)

            # Job ì •ë¦¬
            await self._cleanup_job(job_name)

            # ë¡œê·¸ ì €ì¥
            logs_file = work_directory / f"k8s_job_logs_{execution_id}.txt"
            with open(logs_file, 'w', encoding='utf-8') as f:
                f.write(logs)

            return {
                "execution_mode": "kubernetes",
                "job_name": job_name,
                "container_image": image,
                "output": {"raw_output": logs},
                "logs_path": str(logs_file)
            }

        except Exception as e:
            raise SimulationExecutionError(f"Kubernetes execution failed: {e}") from e

    def _create_k8s_job_manifest(self,
                                image: str,
                                input_data: Dict[str, Any],
                                work_directory: Path,
                                execution_id: str) -> Dict[str, Any]:
        """Kubernetes Job ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""

        job_name = f"simulation-{execution_id}"

        # í™˜ê²½ ë³€ìˆ˜ êµ¬ì„±
        env_vars = []
        for key, value in input_data.get("parameters", {}).items():
            env_vars.append({
                "name": key.upper(),
                "value": str(value)
            })

        return {
            "apiVersion": "batch/v1",
            "kind": "Job",
            "metadata": {
                "name": job_name,
                "labels": {
                    "app": "querygoal-simulation",
                    "execution-id": execution_id
                }
            },
            "spec": {
                "ttlSecondsAfterFinished": 300,  # 5ë¶„ í›„ ìë™ ì‚­ì œ
                "template": {
                    "spec": {
                        "containers": [{
                            "name": "simulation",
                            "image": image,
                            "env": env_vars,
                            "volumeMounts": [{
                                "name": "workspace",
                                "mountPath": "/workspace"
                            }],
                            "resources": {
                                "limits": {
                                    "memory": "2Gi",
                                    "cpu": "1000m"
                                },
                                "requests": {
                                    "memory": "1Gi",
                                    "cpu": "500m"
                                }
                            }
                        }],
                        "volumes": [{
                            "name": "workspace",
                            "persistentVolumeClaim": {
                                "claimName": "querygoal-workspace"
                            }
                        }],
                        "restartPolicy": "Never"
                    }
                },
                "backoffLimit": 2
            }
        }

    async def _wait_for_job_completion(self, job_name: str, timeout: int = 600):
        """Job ì™„ë£Œ ëŒ€ê¸°"""

        for _ in range(timeout // 10):
            # Job ìƒíƒœ í™•ì¸
            status_cmd = ["kubectl", "get", "job", job_name, "-o", "json"]
            process = await asyncio.create_subprocess_exec(
                *status_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await process.communicate()

            if process.returncode == 0:
                job_status = json.loads(stdout.decode('utf-8'))
                conditions = job_status.get("status", {}).get("conditions", [])

                for condition in conditions:
                    if condition["type"] == "Complete" and condition["status"] == "True":
                        logger.info(f"âœ… K8s Job {job_name} completed successfully")
                        return
                    elif condition["type"] == "Failed" and condition["status"] == "True":
                        raise SimulationExecutionError(f"K8s Job {job_name} failed")

            await asyncio.sleep(10)

        raise SimulationExecutionError(f"K8s Job {job_name} timed out after {timeout}s")

    async def _get_job_logs(self, job_name: str) -> str:
        """Job ë¡œê·¸ ìˆ˜ì§‘"""

        logs_cmd = ["kubectl", "logs", f"job/{job_name}"]
        process = await asyncio.create_subprocess_exec(
            *logs_cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        stdout, stderr = await process.communicate()
        return stdout.decode('utf-8', errors='replace')

    async def _cleanup_job(self, job_name: str):
        """Job ì •ë¦¬"""

        delete_cmd = ["kubectl", "delete", "job", job_name]
        process = await asyncio.create_subprocess_exec(
            *delete_cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        await process.communicate()
```

## ğŸ“‹ Phase 4: API í†µí•© ë° í…ŒìŠ¤íŠ¸ (ì£¼ 7-8)

### Task 4.1: API í†µí•© (1ì¼)

#### API ì—…ë°ì´íŠ¸: `api/main.py` ìˆ˜ì •
```python
# ê¸°ì¡´ execute-goal ì—”ë“œí¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
from querygoal.runtime.executor import QueryGoalExecutor

@app.post("/execute-goal-runtime", response_model=ApiResponse)
async def execute_goal_runtime(request: DslRequest):
    """QueryGoal Runtime Executorë¥¼ ì‚¬ìš©í•œ ì‹¤í–‰"""
    if not planner or not agent:
         raise HTTPException(status_code=503, detail="Server is not ready.")

    try:
        # 1ë‹¨ê³„: QueryGoal ìƒì„± (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸)
        from querygoal.pipeline.orchestrator import PipelineOrchestrator
        orchestrator = PipelineOrchestrator()
        querygoal = orchestrator.process_natural_language(request.goal)

        # 2ë‹¨ê³„: Runtime ì‹¤í–‰ (ìƒˆë¡œìš´ Executor)
        runtime_executor = QueryGoalExecutor()
        execution_result = await runtime_executor.execute_querygoal(querygoal)

        return ApiResponse(
            goal=request.goal,
            params=request.dict(),
            result=execution_result,
            runtime_execution=True
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Runtime execution failed: {e}")
```

### Task 4.2: í†µí•© í…ŒìŠ¤íŠ¸ (2ì¼)

#### í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸: `tests/test_runtime_executor.py`
```python
"""
QueryGoal Runtime Executor í†µí•© í…ŒìŠ¤íŠ¸
"""
import asyncio
import pytest
from pathlib import Path
import tempfile

from querygoal.pipeline.orchestrator import PipelineOrchestrator
from querygoal.runtime.executor import QueryGoalExecutor

class TestRuntimeExecutor:
    """Runtime Executor í†µí•© í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    async def sample_querygoal(self):
        """í…ŒìŠ¤íŠ¸ìš© QueryGoal ìƒì„±"""
        orchestrator = PipelineOrchestrator()
        querygoal = orchestrator.process_natural_language(
            "Predict production time for product ABC123 quantity 50"
        )
        return querygoal

    @pytest.mark.asyncio
    async def test_goal3_full_execution(self, sample_querygoal):
        """Goal3 ì „ì²´ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""

        executor = QueryGoalExecutor()

        # Runtime ì‹¤í–‰
        result = await executor.execute_querygoal(sample_querygoal)

        # ê²°ê³¼ ê²€ì¦
        assert result["executionLog"]["status"] == "completed"
        assert "results" in result
        assert "swrlSelection" in result["results"]
        assert "yamlBinding" in result["results"]
        assert "simulation" in result["results"]

    @pytest.mark.asyncio
    async def test_stage_gate_validation(self, sample_querygoal):
        """Stage-Gate ê²€ì¦ í…ŒìŠ¤íŠ¸"""

        executor = QueryGoalExecutor()

        # Stage-Gate ê¸°ì¤€ ìˆ˜ì • (ì‹¤íŒ¨í•˜ë„ë¡)
        executor.stage_criteria["simulation"]["success_criteria"] = lambda r: False

        # ì‹¤í–‰ ì‹œ Stage-Gate ì‹¤íŒ¨ ì˜ˆìƒ
        with pytest.raises(Exception) as exc_info:
            await executor.execute_querygoal(sample_querygoal)

        assert "Stage-Gate" in str(exc_info.value)

if __name__ == "__main__":
    # ê°„ë‹¨í•œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    async def main():
        orchestrator = PipelineOrchestrator()
        querygoal = orchestrator.process_natural_language(
            "Predict production time for product TEST123 quantity 25"
        )

        executor = QueryGoalExecutor()
        result = await executor.execute_querygoal(querygoal)

        print("ğŸ‰ Runtime Execution Test Completed!")
        print(f"Status: {result['executionLog']['status']}")
        print(f"Stages: {len(result['executionLog']['stages'])}")

    asyncio.run(main())
```

## ğŸ¯ êµ¬í˜„ ì™„ë£Œ í›„ ë‹¬ì„± íš¨ê³¼

### 1. ì™„ì „í•œ End-to-End ì‹¤í–‰
```
ìì—°ì–´ ì…ë ¥ â†’ QueryGoal ìƒì„± â†’ Runtime ì‹¤í–‰ â†’ ì‹¤ì œ ê²°ê³¼ ìƒì„±
```

### 2. Production-Ready ì•„í‚¤í…ì²˜
- Stage-Gate ê¸°ë°˜ ì‹ ë¢°ì„± í™•ë³´
- AAS ì„œë²„ ì‹¤ì œ ì—°ë™
- ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
- í™•ì¥ ê°€ëŠ¥í•œ í•¸ë“¤ëŸ¬ ì‹œìŠ¤í…œ

### 3. í™•ì¥ì„± ë° ì¬ì‚¬ìš©ì„±
- ë‹¤ë¥¸ Goal ìœ í˜•ì—ë„ ì ìš© ê°€ëŠ¥
- ìƒˆë¡œìš´ Stage í•¸ë“¤ëŸ¬ ì‰½ê²Œ ì¶”ê°€
- Docker/Kubernetes í™˜ê²½ ì„ íƒ ê°€ëŠ¥

## ğŸ“… 8ì£¼ ì‹¤í–‰ ê³„íš

| ì£¼ì°¨ | Phase | ì£¼ìš” ì‘ì—… | ì‚°ì¶œë¬¼ |
|------|-------|----------|--------|
| 1-2 | Phase 1 | QueryGoalExecutor + Base Handler | ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°, ê¸°ë³¸ êµ¬ì¡° |
| 3-4 | Phase 2 | Goal3 Stage í•¸ë“¤ëŸ¬ | 3ê°œ í•¸ë“¤ëŸ¬ í´ë˜ìŠ¤ |
| 5-6 | Phase 3 | ê³µí†µ ëŸ°íƒ€ì„ ì»´í¬ë„ŒíŠ¸ | AAS Client, Container Client |
| 7-8 | Phase 4 | API í†µí•© ë° í…ŒìŠ¤íŠ¸ | API ì—…ë°ì´íŠ¸, í†µí•© í…ŒìŠ¤íŠ¸ |

**ì´ ê³„íšì„ ì™„ë£Œí•˜ë©´ QueryGoal ì‹œìŠ¤í…œì´ ì‹¤ì œ ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ í™˜ê²½ì—ì„œ ìì—°ì–´ ì…ë ¥ë¶€í„° ì‹¤ì œ ê²°ê³¼ ìƒì„±ê¹Œì§€ì˜ ì™„ì „í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤!** ğŸ­ğŸš€